

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Statistical Model &mdash; Machine Learning Explorations 1.0.0 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Hypothesis Testing" href="Hypothesis.html" />
    <link rel="prev" title="Statisitcs" href="Statistics.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Machine Learning Explorations
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Statistics.html">Statisitcs</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Statistical Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#linear-models">Linear Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="#linear-regression">Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="#non-linear-models">Non-Linear Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="#design-matrices">Design Matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="#creating-a-model">Creating a Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#using-statsmodel-library">using statsmodel library</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#fitting-a-model">Fitting a Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#view-model-summary">View Model Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="#construct-design-matrices">Construct Design Matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="#design-matrix-with-numpy">Design Matrix with Numpy</a></li>
<li class="toctree-l2"><a class="reference internal" href="#design-matrix-with-patsy">Design Matrix with patsy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#load-popular-datasets-from-statsmodels">load popular datasets from statsmodels</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#linear-model-creation-using-statsmodels">Linear Model Creation using statsmodels</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#using-inbuilt-icecream-dataset">Using inbuilt  Icecream  dataset</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#logistic-regression">Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="#poisson-regression-model">Poisson Regression Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#anova">Anova</a></li>
<li class="toctree-l2"><a class="reference internal" href="#anova-and-f-statistics">ANOVA and F-statistics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#f-distribution-f-statistics-and-f-test">F-Distribution ,F-Statistics and F-test</a></li>
<li class="toctree-l3"><a class="reference internal" href="#determine-f-value">Determine F-Value</a></li>
<li class="toctree-l3"><a class="reference internal" href="#f-statistics-mean-square-of-model-mean-square-of-the-residual">F-statistics = Mean square of model / Mean square of the residual</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Hypothesis.html">Hypothesis Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualization.html">Matplotlib Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="plot_learning_curve.html">Plotting Learning Curves</a></li>
<li class="toctree-l1"><a class="reference internal" href="BostonDataModelling.html">Boston Data Modelling</a></li>
<li class="toctree-l1"><a class="reference internal" href="BreastCancerPreprocessingAnalysis.html">Breast Cancer Preprocessing Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="BreastCancerModellingAnalysis.html">Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="BreastCancerModellingAnalysis.html#clustering">Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="ChurnClassificationModelling.html">Churn Classification Modelling</a></li>
<li class="toctree-l1"><a class="reference internal" href="DigitsDataModelling.html">Digits Data Analysis and Modelling</a></li>
<li class="toctree-l1"><a class="reference internal" href="IrisDataModelling.html">Iris Data Modelling</a></li>
<li class="toctree-l1"><a class="reference internal" href="PandasExploration.html">Pandas Exploration</a></li>
<li class="toctree-l1"><a class="reference internal" href="NLTK.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="SpamDataAnalytics.html">Spam Data Analytics</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Machine Learning Explorations</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Statistical Model</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/StatisticalModelling.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="statistical-model">
<h1>Statistical Model<a class="headerlink" href="#statistical-model" title="Permalink to this headline">¶</a></h1>
<ul>
<li><p>Mathematical equation which explains the relationship between
dependent variable (Y) and independent variable(X).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Due to uncertainy in result and noise the equation is</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">e</span>
</pre></div>
</div>
</li>
</ul>
<div class="section" id="linear-models">
<h2>Linear Models<a class="headerlink" href="#linear-models" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Y = θ0 + θ1 * X1 + θ2 * X2 + … + θn * Xn</p></li>
<li><p>Y = θ0 + θ1 * X + θ2 * X^2 + … + θn * X^n</p></li>
<li><p>Y = θ0 + θ1 * sin(X1) + θ2 * cos(X2)</p></li>
</ul>
</div>
<div class="section" id="linear-regression">
<h2>Linear Regression<a class="headerlink" href="#linear-regression" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">θ0</span> <span class="o">+</span> <span class="n">θ1</span> <span class="o">*</span> <span class="n">X</span> <span class="o">+</span> <span class="n">e</span>

<span class="n">θ0</span><span class="p">,</span> <span class="n">θ1</span> <span class="o">=</span> <span class="n">Coefficient</span>
<span class="n">e</span> <span class="o">=</span> <span class="n">normally</span> <span class="n">distributed</span> <span class="n">residual</span> <span class="n">error</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Linear Regression model assumes that residuals are independent and
normally distributed</p></li>
<li><p>Model is fitted to the data using ordinary least squares approach</p></li>
</ul>
</div>
<div class="section" id="non-linear-models">
<h2>Non-Linear Models<a class="headerlink" href="#non-linear-models" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Most of the cases, the non-linear models are generalized to linear
models</p></li>
<li><p>Binomial Regresson, Poisson Regression</p></li>
</ul>
</div>
<div class="section" id="design-matrices">
<h2>Design Matrices<a class="headerlink" href="#design-matrices" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Once the model is chosen design metrices are constructed. Y = XB + e</p></li>
</ul>
<table class="docutils align-default">
<colgroup>
<col style="width: 18%" />
<col style="width: 82%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Variable</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Y</p></td>
<td><p>vector/matrix of dependent variable</p></td>
</tr>
<tr class="row-odd"><td><p>X</p></td>
<td><p>vector/matrix of independent variable</p></td>
</tr>
<tr class="row-even"><td><p>B</p></td>
<td><p>vector/matrix of coefficient</p></td>
</tr>
<tr class="row-odd"><td><p>e</p></td>
<td><p>residual error</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="creating-a-model">
<h2>Creating a Model<a class="headerlink" href="#creating-a-model" title="Permalink to this headline">¶</a></h2>
<div class="section" id="using-statsmodel-library">
<h3>using statsmodel library<a class="headerlink" href="#using-statsmodel-library" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p>OLS (oridinart least squares)</p></li>
<li><p>GLM (genralized linear model)</p></li>
<li><p>WLS (weighted least squares)</p></li>
<li><p>ols</p></li>
<li><p>glm</p></li>
<li><p>wls</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Uppercase</span> <span class="n">names</span> <span class="n">take</span> <span class="n">design</span> <span class="n">metrices</span> <span class="k">as</span> <span class="n">args</span>
<span class="n">Lowercase</span> <span class="n">names</span> <span class="n">take</span> <span class="n">Patsy</span> <span class="n">formulas</span> <span class="ow">and</span> <span class="n">dataframes</span> <span class="k">as</span> <span class="n">args</span>
</pre></div>
</div>
</li>
</ul>
</div>
</div>
<div class="section" id="fitting-a-model">
<h2>Fitting a Model<a class="headerlink" href="#fitting-a-model" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>fitting method returns a model object for futher methods, attributes
and coefficient matrix for analysis</p></li>
</ul>
</div>
<div class="section" id="view-model-summary">
<h2>View Model Summary<a class="headerlink" href="#view-model-summary" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Describe the fit description of the model in text.</p></li>
</ul>
<hr></div>
<div class="section" id="construct-design-matrices">
<h2>Construct Design Matrices<a class="headerlink" href="#construct-design-matrices" title="Permalink to this headline">¶</a></h2>
<p>Y = θ0 + θ1 * X1 + θ2 * X2 + θ3 * X1 * X2</p>
</div>
<div class="section" id="design-matrix-with-numpy">
<h2>Design Matrix with Numpy<a class="headerlink" href="#design-matrix-with-numpy" title="Permalink to this headline">¶</a></h2>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">])</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">13</span><span class="p">,</span><span class="mi">14</span><span class="p">,</span><span class="mi">15</span><span class="p">])</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x1</span><span class="o">*</span><span class="n">x2</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>

<span class="nb">print</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span><span class="mi">1</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">2</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">3</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">4</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">5</span><span class="p">]]</span>
<span class="p">[[</span>  <span class="mf">1.</span>   <span class="mf">6.</span>  <span class="mf">11.</span>  <span class="mf">66.</span><span class="p">]</span>
 <span class="p">[</span>  <span class="mf">1.</span>   <span class="mf">7.</span>  <span class="mf">12.</span>  <span class="mf">84.</span><span class="p">]</span>
 <span class="p">[</span>  <span class="mf">1.</span>   <span class="mf">8.</span>  <span class="mf">13.</span> <span class="mf">104.</span><span class="p">]</span>
 <span class="p">[</span>  <span class="mf">1.</span>   <span class="mf">9.</span>  <span class="mf">14.</span> <span class="mf">126.</span><span class="p">]</span>
 <span class="p">[</span>  <span class="mf">1.</span>  <span class="mf">10.</span>  <span class="mf">15.</span> <span class="mf">150.</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="section" id="design-matrix-with-patsy">
<h2>Design Matrix with patsy<a class="headerlink" href="#design-matrix-with-patsy" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>allows defining a model easily</p></li>
<li><p>constructs relevant design matrices (patsy.dmatrices)</p></li>
<li><p>takes a formula in string form as arg and a dictionary like object
with data arrays for resoponse variables</p></li>
</ul>
<div class="figure align-default" id="id1">
<img alt="image" src="https://patsy.readthedocs.io/en/v0.1.0/_images/formula-structure.png" />
<p class="caption"><span class="caption-text">image</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="o">~</span>
 <span class="o">/</span>    \
<span class="n">Y</span>     <span class="o">+</span>
    <span class="o">/</span>   \
   <span class="mi">1</span>     <span class="o">+</span>
       <span class="o">/</span>   \
      <span class="n">x1</span>    <span class="o">+</span>
          <span class="o">/</span>   \
        <span class="n">x2</span>     <span class="o">*</span>
             <span class="o">/</span>   \
           <span class="n">x1</span>    <span class="n">x2</span>
</pre></div>
</div>
<ul class="simple">
<li><p>‘y ~ np.log(x1)’: Often numpy functions can be used to transform
terms in the expression.</p></li>
<li><p>‘y ~ I(x1 + x2)’: I is the identify function, used to escape
arithmetic expressions and are evaluated.</p></li>
<li><p>‘y ~ C(x1)’: Treats the variable x1 as a categorical variable.</p></li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">patsy</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">])</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Y&#39;</span> <span class="p">:</span> <span class="n">Y</span><span class="p">,</span>
    <span class="s1">&#39;x1&#39;</span> <span class="p">:</span> <span class="n">x1</span><span class="p">,</span>
    <span class="s1">&#39;x2&#39;</span> <span class="p">:</span> <span class="n">x2</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">equation</span> <span class="o">=</span> <span class="s1">&#39;Y ~ 1 + x1 + x2 + x1*x2&#39;</span>

<span class="n">Y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">patsy</span><span class="o">.</span><span class="n">dmatrices</span><span class="p">(</span><span class="n">equation</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span><span class="mf">1.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">2.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">3.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">4.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">5.</span><span class="p">]]</span>
<span class="p">[[</span>  <span class="mf">1.</span>   <span class="mf">6.</span>  <span class="mf">11.</span>  <span class="mf">66.</span><span class="p">]</span>
 <span class="p">[</span>  <span class="mf">1.</span>   <span class="mf">7.</span>  <span class="mf">12.</span>  <span class="mf">84.</span><span class="p">]</span>
 <span class="p">[</span>  <span class="mf">1.</span>   <span class="mf">8.</span>  <span class="mf">13.</span> <span class="mf">104.</span><span class="p">]</span>
 <span class="p">[</span>  <span class="mf">1.</span>   <span class="mf">9.</span>  <span class="mf">14.</span> <span class="mf">126.</span><span class="p">]</span>
 <span class="p">[</span>  <span class="mf">1.</span>  <span class="mf">10.</span>  <span class="mf">15.</span> <span class="mf">150.</span><span class="p">]]</span>
</pre></div>
</div>
<div class="section" id="load-popular-datasets-from-statsmodels">
<h3>load popular datasets from statsmodels<a class="headerlink" href="#load-popular-datasets-from-statsmodels" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">cancer</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="c1"># dataset = sm.datasets.cancer.load_pandas()</span>
<span class="n">dataset</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;statsmodels.datasets.utils.Dataset&#39;&gt;
</pre></div>
</div>
<hr/></div>
</div>
<div class="section" id="linear-model-creation-using-statsmodels">
<h2>Linear Model Creation using statsmodels<a class="headerlink" href="#linear-model-creation-using-statsmodels" title="Permalink to this headline">¶</a></h2>
<div class="section" id="using-inbuilt-icecream-dataset">
<h3>Using inbuilt  Icecream  dataset<a class="headerlink" href="#using-inbuilt-icecream-dataset" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>

<span class="n">icecream</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">get_rdataset</span><span class="p">(</span><span class="s2">&quot;Icecream&quot;</span><span class="p">,</span><span class="s2">&quot;Ecdat&quot;</span><span class="p">)</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">icecream</span><span class="o">.</span><span class="n">data</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cons</th>
      <th>income</th>
      <th>price</th>
      <th>temp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.386</td>
      <td>78</td>
      <td>0.270</td>
      <td>41</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.374</td>
      <td>79</td>
      <td>0.282</td>
      <td>56</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.393</td>
      <td>81</td>
      <td>0.277</td>
      <td>63</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.425</td>
      <td>80</td>
      <td>0.280</td>
      <td>68</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.406</td>
      <td>76</td>
      <td>0.272</td>
      <td>69</td>
    </tr>
  </tbody>
</table>
</div><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>

<span class="n">linearModel1</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;cons ~ price + temp&#39;</span><span class="p">,</span><span class="n">dataset</span><span class="p">)</span>

<span class="n">fitModel1</span> <span class="o">=</span> <span class="n">linearModel1</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">fitModel1</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>                            <span class="n">OLS</span> <span class="n">Regression</span> <span class="n">Results</span>
<span class="o">==============================================================================</span>
<span class="n">Dep</span><span class="o">.</span> <span class="n">Variable</span><span class="p">:</span>                   <span class="n">cons</span>   <span class="n">R</span><span class="o">-</span><span class="n">squared</span><span class="p">:</span>                       <span class="mf">0.633</span>
<span class="n">Model</span><span class="p">:</span>                            <span class="n">OLS</span>   <span class="n">Adj</span><span class="o">.</span> <span class="n">R</span><span class="o">-</span><span class="n">squared</span><span class="p">:</span>                  <span class="mf">0.606</span>
<span class="n">Method</span><span class="p">:</span>                 <span class="n">Least</span> <span class="n">Squares</span>   <span class="n">F</span><span class="o">-</span><span class="n">statistic</span><span class="p">:</span>                     <span class="mf">23.27</span>
<span class="n">Date</span><span class="p">:</span>                <span class="n">Thu</span><span class="p">,</span> <span class="mi">15</span> <span class="n">Oct</span> <span class="mi">2020</span>   <span class="n">Prob</span> <span class="p">(</span><span class="n">F</span><span class="o">-</span><span class="n">statistic</span><span class="p">):</span>           <span class="mf">1.34e-06</span>
<span class="n">Time</span><span class="p">:</span>                        <span class="mi">21</span><span class="p">:</span><span class="mi">53</span><span class="p">:</span><span class="mi">43</span>   <span class="n">Log</span><span class="o">-</span><span class="n">Likelihood</span><span class="p">:</span>                 <span class="mf">54.607</span>
<span class="n">No</span><span class="o">.</span> <span class="n">Observations</span><span class="p">:</span>                  <span class="mi">30</span>   <span class="n">AIC</span><span class="p">:</span>                            <span class="o">-</span><span class="mf">103.2</span>
<span class="n">Df</span> <span class="n">Residuals</span><span class="p">:</span>                      <span class="mi">27</span>   <span class="n">BIC</span><span class="p">:</span>                            <span class="o">-</span><span class="mf">99.01</span>
<span class="n">Df</span> <span class="n">Model</span><span class="p">:</span>                           <span class="mi">2</span>
<span class="n">Covariance</span> <span class="n">Type</span><span class="p">:</span>            <span class="n">nonrobust</span>
<span class="o">==============================================================================</span>
                 <span class="n">coef</span>    <span class="n">std</span> <span class="n">err</span>          <span class="n">t</span>      <span class="n">P</span><span class="o">&gt;|</span><span class="n">t</span><span class="o">|</span>      <span class="p">[</span><span class="mf">0.025</span>      <span class="mf">0.975</span><span class="p">]</span>
<span class="o">------------------------------------------------------------------------------</span>
<span class="n">Intercept</span>      <span class="mf">0.5966</span>      <span class="mf">0.258</span>      <span class="mf">2.309</span>      <span class="mf">0.029</span>       <span class="mf">0.067</span>       <span class="mf">1.127</span>
<span class="n">price</span>         <span class="o">-</span><span class="mf">1.4018</span>      <span class="mf">0.925</span>     <span class="o">-</span><span class="mf">1.515</span>      <span class="mf">0.141</span>      <span class="o">-</span><span class="mf">3.300</span>       <span class="mf">0.496</span>
<span class="n">temp</span>           <span class="mf">0.0030</span>      <span class="mf">0.000</span>      <span class="mf">6.448</span>      <span class="mf">0.000</span>       <span class="mf">0.002</span>       <span class="mf">0.004</span>
<span class="o">==============================================================================</span>
<span class="n">Omnibus</span><span class="p">:</span>                        <span class="mf">0.991</span>   <span class="n">Durbin</span><span class="o">-</span><span class="n">Watson</span><span class="p">:</span>                   <span class="mf">0.656</span>
<span class="n">Prob</span><span class="p">(</span><span class="n">Omnibus</span><span class="p">):</span>                  <span class="mf">0.609</span>   <span class="n">Jarque</span><span class="o">-</span><span class="n">Bera</span> <span class="p">(</span><span class="n">JB</span><span class="p">):</span>                <span class="mf">0.220</span>
<span class="n">Skew</span><span class="p">:</span>                          <span class="o">-</span><span class="mf">0.107</span>   <span class="n">Prob</span><span class="p">(</span><span class="n">JB</span><span class="p">):</span>                        <span class="mf">0.896</span>
<span class="n">Kurtosis</span><span class="p">:</span>                       <span class="mf">3.361</span>   <span class="n">Cond</span><span class="o">.</span> <span class="n">No</span><span class="o">.</span>                     <span class="mf">6.58e+03</span>
<span class="o">==============================================================================</span>

<span class="n">Warnings</span><span class="p">:</span>
<span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="n">Standard</span> <span class="n">Errors</span> <span class="n">assume</span> <span class="n">that</span> <span class="n">the</span> <span class="n">covariance</span> <span class="n">matrix</span> <span class="n">of</span> <span class="n">the</span> <span class="n">errors</span> <span class="ow">is</span> <span class="n">correctly</span> <span class="n">specified</span><span class="o">.</span>
<span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="n">The</span> <span class="n">condition</span> <span class="n">number</span> <span class="ow">is</span> <span class="n">large</span><span class="p">,</span> <span class="mf">6.58e+03</span><span class="o">.</span> <span class="n">This</span> <span class="n">might</span> <span class="n">indicate</span> <span class="n">that</span> <span class="n">there</span> <span class="n">are</span>
<span class="n">strong</span> <span class="n">multicollinearity</span> <span class="ow">or</span> <span class="n">other</span> <span class="n">numerical</span> <span class="n">problems</span><span class="o">.</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">linearModel2</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;cons ~ income + temp&#39;</span><span class="p">,</span><span class="n">dataset</span><span class="p">)</span>

<span class="n">fitModel2</span> <span class="o">=</span> <span class="n">linearModel2</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">fitModel2</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>                            <span class="n">OLS</span> <span class="n">Regression</span> <span class="n">Results</span>
<span class="o">==============================================================================</span>
<span class="n">Dep</span><span class="o">.</span> <span class="n">Variable</span><span class="p">:</span>                   <span class="n">cons</span>   <span class="n">R</span><span class="o">-</span><span class="n">squared</span><span class="p">:</span>                       <span class="mf">0.702</span>
<span class="n">Model</span><span class="p">:</span>                            <span class="n">OLS</span>   <span class="n">Adj</span><span class="o">.</span> <span class="n">R</span><span class="o">-</span><span class="n">squared</span><span class="p">:</span>                  <span class="mf">0.680</span>
<span class="n">Method</span><span class="p">:</span>                 <span class="n">Least</span> <span class="n">Squares</span>   <span class="n">F</span><span class="o">-</span><span class="n">statistic</span><span class="p">:</span>                     <span class="mf">31.81</span>
<span class="n">Date</span><span class="p">:</span>                <span class="n">Thu</span><span class="p">,</span> <span class="mi">15</span> <span class="n">Oct</span> <span class="mi">2020</span>   <span class="n">Prob</span> <span class="p">(</span><span class="n">F</span><span class="o">-</span><span class="n">statistic</span><span class="p">):</span>           <span class="mf">7.96e-08</span>
<span class="n">Time</span><span class="p">:</span>                        <span class="mi">21</span><span class="p">:</span><span class="mi">53</span><span class="p">:</span><span class="mi">43</span>   <span class="n">Log</span><span class="o">-</span><span class="n">Likelihood</span><span class="p">:</span>                 <span class="mf">57.742</span>
<span class="n">No</span><span class="o">.</span> <span class="n">Observations</span><span class="p">:</span>                  <span class="mi">30</span>   <span class="n">AIC</span><span class="p">:</span>                            <span class="o">-</span><span class="mf">109.5</span>
<span class="n">Df</span> <span class="n">Residuals</span><span class="p">:</span>                      <span class="mi">27</span>   <span class="n">BIC</span><span class="p">:</span>                            <span class="o">-</span><span class="mf">105.3</span>
<span class="n">Df</span> <span class="n">Model</span><span class="p">:</span>                           <span class="mi">2</span>
<span class="n">Covariance</span> <span class="n">Type</span><span class="p">:</span>            <span class="n">nonrobust</span>
<span class="o">==============================================================================</span>
                 <span class="n">coef</span>    <span class="n">std</span> <span class="n">err</span>          <span class="n">t</span>      <span class="n">P</span><span class="o">&gt;|</span><span class="n">t</span><span class="o">|</span>      <span class="p">[</span><span class="mf">0.025</span>      <span class="mf">0.975</span><span class="p">]</span>
<span class="o">------------------------------------------------------------------------------</span>
<span class="n">Intercept</span>     <span class="o">-</span><span class="mf">0.1132</span>      <span class="mf">0.108</span>     <span class="o">-</span><span class="mf">1.045</span>      <span class="mf">0.305</span>      <span class="o">-</span><span class="mf">0.335</span>       <span class="mf">0.109</span>
<span class="n">income</span>         <span class="mf">0.0035</span>      <span class="mf">0.001</span>      <span class="mf">3.017</span>      <span class="mf">0.006</span>       <span class="mf">0.001</span>       <span class="mf">0.006</span>
<span class="n">temp</span>           <span class="mf">0.0035</span>      <span class="mf">0.000</span>      <span class="mf">7.963</span>      <span class="mf">0.000</span>       <span class="mf">0.003</span>       <span class="mf">0.004</span>
<span class="o">==============================================================================</span>
<span class="n">Omnibus</span><span class="p">:</span>                        <span class="mf">2.264</span>   <span class="n">Durbin</span><span class="o">-</span><span class="n">Watson</span><span class="p">:</span>                   <span class="mf">1.003</span>
<span class="n">Prob</span><span class="p">(</span><span class="n">Omnibus</span><span class="p">):</span>                  <span class="mf">0.322</span>   <span class="n">Jarque</span><span class="o">-</span><span class="n">Bera</span> <span class="p">(</span><span class="n">JB</span><span class="p">):</span>                <span class="mf">1.094</span>
<span class="n">Skew</span><span class="p">:</span>                           <span class="mf">0.386</span>   <span class="n">Prob</span><span class="p">(</span><span class="n">JB</span><span class="p">):</span>                        <span class="mf">0.579</span>
<span class="n">Kurtosis</span><span class="p">:</span>                       <span class="mf">3.528</span>   <span class="n">Cond</span><span class="o">.</span> <span class="n">No</span><span class="o">.</span>                     <span class="mf">1.56e+03</span>
<span class="o">==============================================================================</span>

<span class="n">Warnings</span><span class="p">:</span>
<span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="n">Standard</span> <span class="n">Errors</span> <span class="n">assume</span> <span class="n">that</span> <span class="n">the</span> <span class="n">covariance</span> <span class="n">matrix</span> <span class="n">of</span> <span class="n">the</span> <span class="n">errors</span> <span class="ow">is</span> <span class="n">correctly</span> <span class="n">specified</span><span class="o">.</span>
<span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="n">The</span> <span class="n">condition</span> <span class="n">number</span> <span class="ow">is</span> <span class="n">large</span><span class="p">,</span> <span class="mf">1.56e+03</span><span class="o">.</span> <span class="n">This</span> <span class="n">might</span> <span class="n">indicate</span> <span class="n">that</span> <span class="n">there</span> <span class="n">are</span>
<span class="n">strong</span> <span class="n">multicollinearity</span> <span class="ow">or</span> <span class="n">other</span> <span class="n">numerical</span> <span class="n">problems</span><span class="o">.</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">linearModel3</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;cons ~ -1 + income + temp&#39;</span><span class="p">,</span><span class="n">dataset</span><span class="p">)</span>

<span class="n">fitModel3</span> <span class="o">=</span> <span class="n">linearModel3</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">fitModel3</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>                                 <span class="n">OLS</span> <span class="n">Regression</span> <span class="n">Results</span>
<span class="o">=======================================================================================</span>
<span class="n">Dep</span><span class="o">.</span> <span class="n">Variable</span><span class="p">:</span>                   <span class="n">cons</span>   <span class="n">R</span><span class="o">-</span><span class="n">squared</span> <span class="p">(</span><span class="n">uncentered</span><span class="p">):</span>                   <span class="mf">0.990</span>
<span class="n">Model</span><span class="p">:</span>                            <span class="n">OLS</span>   <span class="n">Adj</span><span class="o">.</span> <span class="n">R</span><span class="o">-</span><span class="n">squared</span> <span class="p">(</span><span class="n">uncentered</span><span class="p">):</span>              <span class="mf">0.990</span>
<span class="n">Method</span><span class="p">:</span>                 <span class="n">Least</span> <span class="n">Squares</span>   <span class="n">F</span><span class="o">-</span><span class="n">statistic</span><span class="p">:</span>                              <span class="mf">1426.</span>
<span class="n">Date</span><span class="p">:</span>                <span class="n">Thu</span><span class="p">,</span> <span class="mi">15</span> <span class="n">Oct</span> <span class="mi">2020</span>   <span class="n">Prob</span> <span class="p">(</span><span class="n">F</span><span class="o">-</span><span class="n">statistic</span><span class="p">):</span>                    <span class="mf">6.77e-29</span>
<span class="n">Time</span><span class="p">:</span>                        <span class="mi">21</span><span class="p">:</span><span class="mi">53</span><span class="p">:</span><span class="mi">43</span>   <span class="n">Log</span><span class="o">-</span><span class="n">Likelihood</span><span class="p">:</span>                          <span class="mf">57.146</span>
<span class="n">No</span><span class="o">.</span> <span class="n">Observations</span><span class="p">:</span>                  <span class="mi">30</span>   <span class="n">AIC</span><span class="p">:</span>                                     <span class="o">-</span><span class="mf">110.3</span>
<span class="n">Df</span> <span class="n">Residuals</span><span class="p">:</span>                      <span class="mi">28</span>   <span class="n">BIC</span><span class="p">:</span>                                     <span class="o">-</span><span class="mf">107.5</span>
<span class="n">Df</span> <span class="n">Model</span><span class="p">:</span>                           <span class="mi">2</span>
<span class="n">Covariance</span> <span class="n">Type</span><span class="p">:</span>            <span class="n">nonrobust</span>
<span class="o">==============================================================================</span>
                 <span class="n">coef</span>    <span class="n">std</span> <span class="n">err</span>          <span class="n">t</span>      <span class="n">P</span><span class="o">&gt;|</span><span class="n">t</span><span class="o">|</span>      <span class="p">[</span><span class="mf">0.025</span>      <span class="mf">0.975</span><span class="p">]</span>
<span class="o">------------------------------------------------------------------------------</span>
<span class="n">income</span>         <span class="mf">0.0023</span>      <span class="mf">0.000</span>      <span class="mf">9.906</span>      <span class="mf">0.000</span>       <span class="mf">0.002</span>       <span class="mf">0.003</span>
<span class="n">temp</span>           <span class="mf">0.0033</span>      <span class="mf">0.000</span>      <span class="mf">8.571</span>      <span class="mf">0.000</span>       <span class="mf">0.003</span>       <span class="mf">0.004</span>
<span class="o">==============================================================================</span>
<span class="n">Omnibus</span><span class="p">:</span>                        <span class="mf">3.584</span>   <span class="n">Durbin</span><span class="o">-</span><span class="n">Watson</span><span class="p">:</span>                   <span class="mf">0.887</span>
<span class="n">Prob</span><span class="p">(</span><span class="n">Omnibus</span><span class="p">):</span>                  <span class="mf">0.167</span>   <span class="n">Jarque</span><span class="o">-</span><span class="n">Bera</span> <span class="p">(</span><span class="n">JB</span><span class="p">):</span>                <span class="mf">2.089</span>
<span class="n">Skew</span><span class="p">:</span>                           <span class="mf">0.508</span>   <span class="n">Prob</span><span class="p">(</span><span class="n">JB</span><span class="p">):</span>                        <span class="mf">0.352</span>
<span class="n">Kurtosis</span><span class="p">:</span>                       <span class="mf">3.798</span>   <span class="n">Cond</span><span class="o">.</span> <span class="n">No</span><span class="o">.</span>                         <span class="mf">6.45</span>
<span class="o">==============================================================================</span>

<span class="n">Warnings</span><span class="p">:</span>
<span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="n">Standard</span> <span class="n">Errors</span> <span class="n">assume</span> <span class="n">that</span> <span class="n">the</span> <span class="n">covariance</span> <span class="n">matrix</span> <span class="n">of</span> <span class="n">the</span> <span class="n">errors</span> <span class="ow">is</span> <span class="n">correctly</span> <span class="n">specified</span><span class="o">.</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">get_rdataset</span><span class="p">(</span><span class="s2">&quot;mtcars&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;np.log(wt) ~ np.log(mpg)&#39;</span><span class="p">,</span><span class="n">df</span><span class="p">)</span>
<span class="n">trainedModel</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">trainedModel</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>                            <span class="n">OLS</span> <span class="n">Regression</span> <span class="n">Results</span>
<span class="o">==============================================================================</span>
<span class="n">Dep</span><span class="o">.</span> <span class="n">Variable</span><span class="p">:</span>             <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">wt</span><span class="p">)</span>   <span class="n">R</span><span class="o">-</span><span class="n">squared</span><span class="p">:</span>                       <span class="mf">0.806</span>
<span class="n">Model</span><span class="p">:</span>                            <span class="n">OLS</span>   <span class="n">Adj</span><span class="o">.</span> <span class="n">R</span><span class="o">-</span><span class="n">squared</span><span class="p">:</span>                  <span class="mf">0.799</span>
<span class="n">Method</span><span class="p">:</span>                 <span class="n">Least</span> <span class="n">Squares</span>   <span class="n">F</span><span class="o">-</span><span class="n">statistic</span><span class="p">:</span>                     <span class="mf">124.4</span>
<span class="n">Date</span><span class="p">:</span>                <span class="n">Thu</span><span class="p">,</span> <span class="mi">15</span> <span class="n">Oct</span> <span class="mi">2020</span>   <span class="n">Prob</span> <span class="p">(</span><span class="n">F</span><span class="o">-</span><span class="n">statistic</span><span class="p">):</span>           <span class="mf">3.41e-12</span>
<span class="n">Time</span><span class="p">:</span>                        <span class="mi">21</span><span class="p">:</span><span class="mi">53</span><span class="p">:</span><span class="mi">48</span>   <span class="n">Log</span><span class="o">-</span><span class="n">Likelihood</span><span class="p">:</span>                 <span class="mf">18.024</span>
<span class="n">No</span><span class="o">.</span> <span class="n">Observations</span><span class="p">:</span>                  <span class="mi">32</span>   <span class="n">AIC</span><span class="p">:</span>                            <span class="o">-</span><span class="mf">32.05</span>
<span class="n">Df</span> <span class="n">Residuals</span><span class="p">:</span>                      <span class="mi">30</span>   <span class="n">BIC</span><span class="p">:</span>                            <span class="o">-</span><span class="mf">29.12</span>
<span class="n">Df</span> <span class="n">Model</span><span class="p">:</span>                           <span class="mi">1</span>
<span class="n">Covariance</span> <span class="n">Type</span><span class="p">:</span>            <span class="n">nonrobust</span>
<span class="o">===============================================================================</span>
                  <span class="n">coef</span>    <span class="n">std</span> <span class="n">err</span>          <span class="n">t</span>      <span class="n">P</span><span class="o">&gt;|</span><span class="n">t</span><span class="o">|</span>      <span class="p">[</span><span class="mf">0.025</span>      <span class="mf">0.975</span><span class="p">]</span>
<span class="o">-------------------------------------------------------------------------------</span>
<span class="n">Intercept</span>       <span class="mf">3.9522</span>      <span class="mf">0.255</span>     <span class="mf">15.495</span>      <span class="mf">0.000</span>       <span class="mf">3.431</span>       <span class="mf">4.473</span>
<span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">mpg</span><span class="p">)</span>    <span class="o">-</span><span class="mf">0.9570</span>      <span class="mf">0.086</span>    <span class="o">-</span><span class="mf">11.152</span>      <span class="mf">0.000</span>      <span class="o">-</span><span class="mf">1.132</span>      <span class="o">-</span><span class="mf">0.782</span>
<span class="o">==============================================================================</span>
<span class="n">Omnibus</span><span class="p">:</span>                        <span class="mf">1.199</span>   <span class="n">Durbin</span><span class="o">-</span><span class="n">Watson</span><span class="p">:</span>                   <span class="mf">1.625</span>
<span class="n">Prob</span><span class="p">(</span><span class="n">Omnibus</span><span class="p">):</span>                  <span class="mf">0.549</span>   <span class="n">Jarque</span><span class="o">-</span><span class="n">Bera</span> <span class="p">(</span><span class="n">JB</span><span class="p">):</span>                <span class="mf">1.159</span>
<span class="n">Skew</span><span class="p">:</span>                           <span class="mf">0.349</span>   <span class="n">Prob</span><span class="p">(</span><span class="n">JB</span><span class="p">):</span>                        <span class="mf">0.560</span>
<span class="n">Kurtosis</span><span class="p">:</span>                       <span class="mf">2.381</span>   <span class="n">Cond</span><span class="o">.</span> <span class="n">No</span><span class="o">.</span>                         <span class="mf">33.5</span>
<span class="o">==============================================================================</span>

<span class="n">Warnings</span><span class="p">:</span>
<span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="n">Standard</span> <span class="n">Errors</span> <span class="n">assume</span> <span class="n">that</span> <span class="n">the</span> <span class="n">covariance</span> <span class="n">matrix</span> <span class="n">of</span> <span class="n">the</span> <span class="n">errors</span> <span class="ow">is</span> <span class="n">correctly</span> <span class="n">specified</span><span class="o">.</span>
</pre></div>
</div>
<hr/></div>
</div>
<div class="section" id="logistic-regression">
<h2>Logistic Regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Logit : Logistic Regression</p></li>
<li><p>MNLogit : Multinomial Logistic Regression</p></li>
<li><p>Poisson : Poisson Regression</p></li>
</ul>
<p>hθ( x ) = g( θT * x )</p>
<p>y = θT</p>
<p>g(x) = 1 / ( 1 + e-y )</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">get_rdataset</span><span class="p">(</span><span class="s1">&#39;iris&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>

<span class="c1">## logistic regression takes only two variables as target</span>
<span class="n">dfSubset</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Species&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;versicolor&quot;</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Species&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;virginica&quot;</span><span class="p">)]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>


<span class="c1">## preprocessing</span>
<span class="c1">## label endoding manually</span>

<span class="n">dfSubset</span><span class="p">[</span><span class="s2">&quot;Species&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dfSubset</span><span class="p">[</span><span class="s1">&#39;Species&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span>
    <span class="s2">&quot;versicolor&quot;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;virginica&quot;</span> <span class="p">:</span> <span class="mi">0</span>
<span class="p">})</span>

<span class="n">dfSubset</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span><span class="s2">&quot;_&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">dfSubset</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>

<span class="c1">## Creating a model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">logit</span><span class="p">(</span><span class="s1">&#39;Species ~ Petal_Length + Petal_Width &#39;</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">dfSubset</span><span class="p">)</span>
<span class="n">trainedModel</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">trainedModel</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>



<span class="c1">## Make Predictions</span>
<span class="n">dfTest</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;Petal_Length&quot;</span> <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.7</span> <span class="o">+</span> <span class="mi">6</span><span class="p">,</span>
    <span class="s2">&quot;Petal_Width&quot;</span> <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.7</span> <span class="o">+</span> <span class="mi">1</span>
<span class="p">})</span>


<span class="n">dfTest</span><span class="p">[</span><span class="s1">&#39;rawSpecies&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trainedModel</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dfTest</span><span class="p">)</span>
<span class="n">dfTest</span><span class="p">[</span><span class="s1">&#39;Species&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dfTest</span><span class="o">.</span><span class="n">rawSpecies</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">x</span><span class="o">&gt;</span><span class="mf">0.5</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;*---- Test data and Predictions ----*&quot;</span><span class="p">)</span>
<span class="n">dfTest</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<pre class="literal-block">Optimization terminated successfully.
         Current function value: 0.102818
         Iterations 10
                           Logit Regression Results
==============================================================================
Dep. Variable:                Species   No. Observations:                  100
Model:                          Logit   Df Residuals:                       97
Method:                           MLE   Df Model:                            2
Date:                Thu, 15 Oct 2020   Pseudo R-squ.:                  0.8517
Time:                        21:53:53   Log-Likelihood:                -10.282
converged:                       True   LL-Null:                       -69.315
Covariance Type:            nonrobust   LLR p-value:                 2.303e-26
================================================================================
                   coef    std err          z      P&gt;|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       45.2723     13.612      3.326      0.001      18.594      71.951
Petal_Length    -5.7545      2.306     -2.496      0.013     -10.274      -1.235
Petal_Width    -10.4467      3.756     -2.782      0.005     -17.808      -3.086
================================================================================

Possibly complete quasi-separation: A fraction 0.34 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.
<em>---- Test data and Predictions ----</em></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Petal_Length</th>
      <th>Petal_Width</th>
      <th>rawSpecies</th>
      <th>Species</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6.437427</td>
      <td>0.075640</td>
      <td>0.999412</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>6.710820</td>
      <td>1.414629</td>
      <td>0.000296</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5.009607</td>
      <td>1.536436</td>
      <td>0.597176</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5.885385</td>
      <td>1.335874</td>
      <td>0.072375</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6.339593</td>
      <td>0.180516</td>
      <td>0.998998</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div>
<div class="section" id="poisson-regression-model">
<h2>Poisson Regression Model<a class="headerlink" href="#poisson-regression-model" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Poisson regression is a generalized linear model form of regression
analysis used to model count data and contingency tables. Poisson
regression assumes the response variable Y has a Poisson
distribution, and assumes the logarithm of its expected value can be
modeled by a linear combination of unknown parameters. A Poisson
regression model is sometimes known as a log-linear model, especially
when used to model contingency tables.</p></li>
<li><p>describes a process where dependent variable refers to success count
of many attempts and each attempt has a very low probability of
success.</p></li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://stats.idre.ucla.edu/stat/data/poisson_sim.csv&quot;</span><span class="p">)</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="s1">&#39;num_awards ~ math + C(prog)&#39;</span><span class="p">,</span><span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">)</span>
<span class="n">trainedModel</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>


<span class="nb">print</span><span class="p">(</span><span class="n">trainedModel</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Optimization</span> <span class="n">terminated</span> <span class="n">successfully</span><span class="o">.</span>
         <span class="n">Current</span> <span class="n">function</span> <span class="n">value</span><span class="p">:</span> <span class="mf">0.913761</span>
         <span class="n">Iterations</span> <span class="mi">6</span>
                          <span class="n">Poisson</span> <span class="n">Regression</span> <span class="n">Results</span>
<span class="o">==============================================================================</span>
<span class="n">Dep</span><span class="o">.</span> <span class="n">Variable</span><span class="p">:</span>             <span class="n">num_awards</span>   <span class="n">No</span><span class="o">.</span> <span class="n">Observations</span><span class="p">:</span>                  <span class="mi">200</span>
<span class="n">Model</span><span class="p">:</span>                        <span class="n">Poisson</span>   <span class="n">Df</span> <span class="n">Residuals</span><span class="p">:</span>                      <span class="mi">196</span>
<span class="n">Method</span><span class="p">:</span>                           <span class="n">MLE</span>   <span class="n">Df</span> <span class="n">Model</span><span class="p">:</span>                            <span class="mi">3</span>
<span class="n">Date</span><span class="p">:</span>                <span class="n">Thu</span><span class="p">,</span> <span class="mi">15</span> <span class="n">Oct</span> <span class="mi">2020</span>   <span class="n">Pseudo</span> <span class="n">R</span><span class="o">-</span><span class="n">squ</span><span class="o">.</span><span class="p">:</span>                  <span class="mf">0.2118</span>
<span class="n">Time</span><span class="p">:</span>                        <span class="mi">21</span><span class="p">:</span><span class="mi">53</span><span class="p">:</span><span class="mi">55</span>   <span class="n">Log</span><span class="o">-</span><span class="n">Likelihood</span><span class="p">:</span>                <span class="o">-</span><span class="mf">182.75</span>
<span class="n">converged</span><span class="p">:</span>                       <span class="kc">True</span>   <span class="n">LL</span><span class="o">-</span><span class="n">Null</span><span class="p">:</span>                       <span class="o">-</span><span class="mf">231.86</span>
<span class="n">Covariance</span> <span class="n">Type</span><span class="p">:</span>            <span class="n">nonrobust</span>   <span class="n">LLR</span> <span class="n">p</span><span class="o">-</span><span class="n">value</span><span class="p">:</span>                 <span class="mf">3.747e-21</span>
<span class="o">================================================================================</span>
                   <span class="n">coef</span>    <span class="n">std</span> <span class="n">err</span>          <span class="n">z</span>      <span class="n">P</span><span class="o">&gt;|</span><span class="n">z</span><span class="o">|</span>      <span class="p">[</span><span class="mf">0.025</span>      <span class="mf">0.975</span><span class="p">]</span>
<span class="o">--------------------------------------------------------------------------------</span>
<span class="n">Intercept</span>       <span class="o">-</span><span class="mf">5.2471</span>      <span class="mf">0.658</span>     <span class="o">-</span><span class="mf">7.969</span>      <span class="mf">0.000</span>      <span class="o">-</span><span class="mf">6.538</span>      <span class="o">-</span><span class="mf">3.957</span>
<span class="n">C</span><span class="p">(</span><span class="n">prog</span><span class="p">)[</span><span class="n">T</span><span class="o">.</span><span class="mi">2</span><span class="p">]</span>     <span class="mf">1.0839</span>      <span class="mf">0.358</span>      <span class="mf">3.025</span>      <span class="mf">0.002</span>       <span class="mf">0.382</span>       <span class="mf">1.786</span>
<span class="n">C</span><span class="p">(</span><span class="n">prog</span><span class="p">)[</span><span class="n">T</span><span class="o">.</span><span class="mi">3</span><span class="p">]</span>     <span class="mf">0.3698</span>      <span class="mf">0.441</span>      <span class="mf">0.838</span>      <span class="mf">0.402</span>      <span class="o">-</span><span class="mf">0.495</span>       <span class="mf">1.234</span>
<span class="n">math</span>             <span class="mf">0.0702</span>      <span class="mf">0.011</span>      <span class="mf">6.619</span>      <span class="mf">0.000</span>       <span class="mf">0.049</span>       <span class="mf">0.091</span>
<span class="o">================================================================================</span>
</pre></div>
</div>
<hr/></div>
<div class="section" id="anova">
<h2>Anova<a class="headerlink" href="#anova" title="Permalink to this headline">¶</a></h2>
<p>Analysis Of Variance</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">from</span> <span class="nn">statsmodels.stats</span> <span class="kn">import</span> <span class="n">anova</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">get_rdataset</span><span class="p">(</span><span class="s2">&quot;Icecream&quot;</span><span class="p">,</span> <span class="s2">&quot;Ecdat&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cons</th>
      <th>income</th>
      <th>price</th>
      <th>temp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.386</td>
      <td>78</td>
      <td>0.270</td>
      <td>41</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.374</td>
      <td>79</td>
      <td>0.282</td>
      <td>56</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.393</td>
      <td>81</td>
      <td>0.277</td>
      <td>63</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.425</td>
      <td>80</td>
      <td>0.280</td>
      <td>68</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.406</td>
      <td>76</td>
      <td>0.272</td>
      <td>69</td>
    </tr>
  </tbody>
</table>
</div><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;cons ~ temp&#39;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span> <span class="n">df</span> <span class="p">)</span>
<span class="n">trainedModel</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>


<span class="c1">## Null Hypothesis</span>
<span class="c1">## H0 : Coefficient of temp is zero</span>

<span class="nb">print</span><span class="p">(</span><span class="n">anova</span><span class="o">.</span><span class="n">anova_lm</span><span class="p">(</span><span class="n">trainedModel</span><span class="p">))</span>

<span class="c1">## Null Hypothesis is rejected</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>            <span class="n">df</span>    <span class="n">sum_sq</span>   <span class="n">mean_sq</span>         <span class="n">F</span>        <span class="n">PR</span><span class="p">(</span><span class="o">&gt;</span><span class="n">F</span><span class="p">)</span>
<span class="n">temp</span>       <span class="mf">1.0</span>  <span class="mf">0.075514</span>  <span class="mf">0.075514</span>  <span class="mf">42.27997</span>  <span class="mf">4.789215e-07</span>
<span class="n">Residual</span>  <span class="mf">28.0</span>  <span class="mf">0.050009</span>  <span class="mf">0.001786</span>       <span class="n">NaN</span>           <span class="n">NaN</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;cons ~ income + temp&#39;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span> <span class="n">df</span> <span class="p">)</span>
<span class="n">trainedModel</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>


<span class="c1">## Null Hypothesis</span>
<span class="c1">## H0 : Coefficient of all independent variables are zero</span>

<span class="nb">print</span><span class="p">(</span><span class="n">anova</span><span class="o">.</span><span class="n">anova_lm</span><span class="p">(</span><span class="n">trainedModel</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>            <span class="n">df</span>    <span class="n">sum_sq</span>   <span class="n">mean_sq</span>          <span class="n">F</span>        <span class="n">PR</span><span class="p">(</span><span class="o">&gt;</span><span class="n">F</span><span class="p">)</span>
<span class="n">income</span>     <span class="mf">1.0</span>  <span class="mf">0.000288</span>  <span class="mf">0.000288</span>   <span class="mf">0.208231</span>  <span class="mf">6.518069e-01</span>
<span class="n">temp</span>       <span class="mf">1.0</span>  <span class="mf">0.087836</span>  <span class="mf">0.087836</span>  <span class="mf">63.413711</span>  <span class="mf">1.470071e-08</span>
<span class="n">Residual</span>  <span class="mf">27.0</span>  <span class="mf">0.037399</span>  <span class="mf">0.001385</span>        <span class="n">NaN</span>           <span class="n">NaN</span>
</pre></div>
</div>
</div>
<div class="section" id="anova-and-f-statistics">
<h2>ANOVA and F-statistics<a class="headerlink" href="#anova-and-f-statistics" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>ANOVA can determine whether the meeans of three or more groups are
different.</p></li>
<li><p>ANOVA uses F-tests to statistically test the equality of means.</p></li>
</ul>
<div class="section" id="f-distribution-f-statistics-and-f-test">
<h3>F-Distribution ,F-Statistics and F-test<a class="headerlink" href="#f-distribution-f-statistics-and-f-test" title="Permalink to this headline">¶</a></h3>
<p>U1 has X2 distribution with ν1 degrees of freedom</p>
<p>U2 has X2 distribution with ν2 degrees of freedom</p>
<p>F = (U1 / ν1 ) / (U1 / ν1 ) has an F Distribution</p>
<p><img alt="image" src="./low_f_dplot.webp" /> <img alt="image1" src="./high_f_dplot.webp" /></p>
</div>
<div class="section" id="determine-f-value">
<h3>Determine F-Value<a class="headerlink" href="#determine-f-value" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="f-statistics-mean-square-of-model-mean-square-of-the-residual">
<h3>F-statistics = Mean square of model / Mean square of the residual<a class="headerlink" href="#f-statistics-mean-square-of-model-mean-square-of-the-residual" title="Permalink to this headline">¶</a></h3>
<p>Mean square of model = sum of square value of all variable / degrees of
freedom</p>
<ul class="simple">
<li><p>Mean square of model = ( 0.000288 + 0.087836 ) / 2 = 0.044062</p></li>
<li><p>F = 0.044062 / 0.001385 = 31.813 = 31.813718411552344</p></li>
<li><p>probability of F-statistics = 7.950691527039557e-08</p></li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="mf">31.813718411552344</span> <span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">27</span><span class="p">))</span>

<span class="c1">## p -value is low</span>
<span class="c1">## Null Hypothesis is rejected</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">7.950691527039557e-08</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### Compare two models</span>

<span class="c1">## anova.anova_lm(model1,model2)</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="Hypothesis.html" class="btn btn-neutral float-right" title="Hypothesis Testing" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="Statistics.html" class="btn btn-neutral float-left" title="Statisitcs" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Nishant Baheti.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>