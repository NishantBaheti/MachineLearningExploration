

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Logistic Regression &mdash; Machine Learning Exploration 1.0.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Decision Tree Algorithm" href="../TreeBasedModels/ExploreDecisionTree.html" />
    <link rel="prev" title="Linear Regression" href="../LinearRegression/Explore.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Machine Learning Exploration
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../PracticalStatistics/Statistics.html">Statisitcs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PracticalStatistics/Statistics.html#Probability-Distributions">Probability Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PracticalStatistics/z_score.html">Z Score</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PracticalStatistics/Hypothesis.html">Hypothesis Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PracticalStatistics/StatisticalModelling.html">Statistical Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PandasExploration/PandasExploration.html">Pandas Exploration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../MatplotlibExploration/visualization.html">Matplotlib Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../MathExploration/SingularValueDecomposition.html">Singular Value Decomposition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../LinearRegression/Explore.html">Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../LinearRegression/Explore.html#Ridge(L2-Regularization)-Regression">Ridge(L2 Regularization) Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../LinearRegression/Explore.html#Lasso(L1-Regularization)-Regression">Lasso(L1 Regularization) Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../LinearRegression/Explore.html#Comparing-Linear,-Lasso,-Ridge-Regression">Comparing Linear, Lasso, Ridge Regression</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Logistic Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Cost-Function">Cost Function</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#The-cross-entropy-loss-function">The cross-entropy loss function</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Sigmoid-Function">Sigmoid Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Gradient-Descent-Algorithm">Gradient Descent Algorithm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Math-Calculation-for-Gradient-Descent">Math Calculation for Gradient Descent</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Logitsic-Regression-without-Regression">Logitsic Regression without Regression</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Batch-Gradient-Descent">Batch Gradient Descent</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Stochastic-Gradient-Descent">Stochastic Gradient Descent</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Logistic-Regression-with-Regularization">Logistic Regression with Regularization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Stochastic Gradient Descent</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">Batch Gradient Descent</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../TreeBasedModels/ExploreDecisionTree.html">Decision Tree Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../TreeBasedModels/ExploreRandomForest.html">Random Forest Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../SupportVectorMachine/Explore.html">Support Vector Machine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../IrisDataAnalysis/IrisDataExploratoryAnalysis.html">Iris Data Exploratory Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../BreastCancerAnalysis/BreastCancerPreprocessingAnalysis.html">Breast Cancer Preprocessing Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../BreastCancerAnalysis/BreastCancerModellingAnalysis.html">Breast Cancer Analytical Modelling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../BreastCancerAnalysis/plot_learning_curve.html">Plotting Learning Curves</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ChurnClassification/ChurnClassificationModelling.html">Churn Classification Modelling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../DigitsDataAnalysis/DigitsDataModelling.html">Digits Data Analysis and Modelling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../NaturalLanguageProcessing/NLTK.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../SpamDetection/SpamDataAnalytics.html">Spam Data Analytics</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Machine Learning Exploration</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Logistic Regression</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/LogisticRegression/Explore.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Logistic-Regression">
<h1>Logistic Regression<a class="headerlink" href="#Logistic-Regression" title="Permalink to this headline">¶</a></h1>
<p>Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression).</p>
<p><img alt="logistic_reg1" src="../_images/logistic_reg1.png" /></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">linear_model_format_X</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">tup</span><span class="o">=</span> <span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span> <span class="p">,</span> <span class="n">X</span> <span class="p">)</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="Cost-Function">
<h2>Cost Function<a class="headerlink" href="#Cost-Function" title="Permalink to this headline">¶</a></h2>
<div class="section" id="The-cross-entropy-loss-function">
<h3>The cross-entropy loss function<a class="headerlink" href="#The-cross-entropy-loss-function" title="Permalink to this headline">¶</a></h3>
<p>We need a loss function that expresses, for an observationx, how close the classifier output</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span> <span class="n">ˆy</span> <span class="o">=</span> <span class="n">σ</span><span class="p">(</span><span class="n">w·x</span><span class="o">+</span><span class="n">b</span><span class="p">)</span> <span class="p">)</span>
</pre></div>
</div>
<p>is to the correct output (y, which is 0 or 1). We’ll call this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">L</span><span class="p">(</span><span class="n">ˆy</span><span class="p">,</span><span class="n">y</span><span class="p">)</span> <span class="o">=</span><span class="n">How</span> <span class="n">much</span>  <span class="n">ˆy</span> <span class="n">differs</span> <span class="kn">from</span> <span class="nn">the</span> <span class="n">true</span> <span class="n">y</span>
</pre></div>
</div>
<p>We do this via a loss function that prefers the correct class labels of the train-ing examples to bemore likely. This is called conditional maximum likelihood estimation: we choose the parametersw,b thatmaximize the log probability ofthe true y labels in the training datagiven the observations x. The resulting loss function is the negative log likelihood loss, generally called the cross-entropy loss.</p>
<p><img alt="logistic_reg_2" src="../_images/logistic_reg2.png" /> <img alt="logistic_reg3" src="../_images/logistic_reg3.png" /></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">calculate_entropy_cost</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>

    <span class="n">part_1</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>

    <span class="n">part_2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="n">cost</span> <span class="o">=</span> <span class="p">(</span> <span class="o">-</span><span class="mi">1</span> <span class="o">/</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">part_1</span> <span class="o">+</span> <span class="n">part_2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cost</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Sigmoid-Function">
<h2>Sigmoid Function<a class="headerlink" href="#Sigmoid-Function" title="Permalink to this headline">¶</a></h2>
<p><img alt="logistic_reg11" src="../_images/logistic_reg11.png" /></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Gradient-Descent-Algorithm">
<h2>Gradient Descent Algorithm<a class="headerlink" href="#Gradient-Descent-Algorithm" title="Permalink to this headline">¶</a></h2>
<p><img alt="logistic_reg4" src="../_images/logistic_reg4.png" /></p>
<p><img alt="logistic_reg_9" src="../_images/logistic_reg9.png" /></p>
<div class="section" id="Math-Calculation-for-Gradient-Descent">
<h3>Math Calculation for Gradient Descent<a class="headerlink" href="#Math-Calculation-for-Gradient-Descent" title="Permalink to this headline">¶</a></h3>
<p><img alt="logistic_reg5" src="../_images/logistic_reg5.png" /></p>
<p><img alt="logistic_reg6" src="../_images/logistic_reg6.png" /></p>
<p><img alt="logistic_reg7" src="../_images/logistic_reg7.png" /></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">LogisticRegression</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.01</span> <span class="p">,</span><span class="n">iterations</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iterations</span> <span class="o">=</span> <span class="n">iterations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_X</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_y</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_theta_history</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cost_history</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_format_X_for_theta_0</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X_i</span><span class="p">):</span>

        <span class="n">X_i</span> <span class="o">=</span> <span class="n">X_i</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_i</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">X_i</span> <span class="o">=</span> <span class="n">X_i</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="kc">False</span> <span class="ow">in</span> <span class="p">(</span><span class="n">X_i</span><span class="p">[</span><span class="o">...</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">tup</span><span class="o">=</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">X_i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span> <span class="p">,</span> <span class="n">X_i</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">X_i</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">X</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_X</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">y</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">theta</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">theta_history</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_theta_history</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">cost_history</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cost_history</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">):</span>
        <span class="n">format_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_X_for_theta_0</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">format_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">format_X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span><span class="p">)</span> <span class="c1"># (m,1) = (m,n) * (n,1)</span>
            <span class="k">return</span> <span class="n">y_pred</span>
        <span class="k">elif</span> <span class="n">format_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">format_X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="c1"># (m,1) = (m,n) * (n,1)</span>
            <span class="k">return</span> <span class="n">y_pred</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Shape is not proper.&quot;</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;BGD&quot;</span><span class="p">,</span> <span class="n">theta_precision</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">regularization</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_X_for_theta_0</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_y</span> <span class="o">=</span> <span class="n">y</span>

        <span class="c1"># number of features+1 because of theta_0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_theta_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cost_history</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;BGD&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">_n</span><span class="p">)</span> <span class="o">*</span> <span class="n">theta_precision</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;random initial θ value :&quot;</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">_theta</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iterations</span><span class="p">):</span>
                <span class="c1"># calculate y_pred</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_X</span><span class="p">)</span>

                <span class="c1"># new θ to replace old θ</span>
                <span class="n">new_theta</span> <span class="o">=</span> <span class="kc">None</span>

                <span class="c1"># simultaneous operation</span>

                <span class="k">if</span> <span class="n">regularization</span><span class="p">:</span>
                    <span class="n">gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span> <span class="p">(</span> <span class="n">y_pred</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y</span> <span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_X</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">)</span>
                    <span class="n">new_theta_0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span><span class="p">[:,[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span>  <span class="n">gradient</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                    <span class="n">new_theta_rest</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span><span class="p">[:,</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">_n</span><span class="p">)]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">penalty</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">_m</span><span class="p">)</span> <span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span>  <span class="n">gradient</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
                    <span class="n">new_theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">new_theta_0</span><span class="p">,</span><span class="n">new_theta_rest</span><span class="p">))</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="n">gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span> <span class="p">(</span> <span class="n">y_pred</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y</span> <span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_X</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">)</span>
                    <span class="n">new_theta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span>  <span class="n">gradient</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">new_theta</span><span class="p">))</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">new_theta</span><span class="p">)):</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;breaking. found inf or nan.&quot;</span><span class="p">)</span>
                    <span class="k">break</span>
                <span class="c1"># override with new θ</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span> <span class="o">=</span> <span class="n">new_theta</span>

                <span class="c1"># calculate cost to put in history</span>
                <span class="n">cost</span> <span class="o">=</span> <span class="n">calculate_entropy_cost</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_X</span><span class="p">),</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_cost_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>

                <span class="c1"># calcualted theta in history</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_theta_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_theta</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;SGD&quot;</span><span class="p">:</span> <span class="c1"># stochastic gradient descent</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">_n</span><span class="p">)</span> <span class="o">*</span> <span class="n">theta_precision</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;random initial θ value :&quot;</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">_theta</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iterations</span><span class="p">):</span>

                <span class="c1"># creating indices for batches</span>
                <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">_m</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

                <span class="c1"># creating batch for this iteration</span>
                <span class="n">X_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_X</span><span class="p">,</span><span class="n">indices</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">y_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_y</span><span class="p">,</span><span class="n">indices</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># calculate y_pred</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>
                <span class="c1"># new θ to replace old θ</span>
                <span class="n">new_theta</span> <span class="o">=</span> <span class="kc">None</span>

                <span class="c1"># simultaneous operation</span>
                <span class="k">if</span> <span class="n">regularization</span><span class="p">:</span>
                    <span class="n">gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span> <span class="p">(</span> <span class="n">y_pred</span> <span class="o">-</span> <span class="n">y_batch</span> <span class="p">)</span> <span class="o">*</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">)</span>
                    <span class="n">new_theta_0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span><span class="p">[:,[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span>  <span class="n">gradient</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                    <span class="n">new_theta_rest</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span><span class="p">[:,</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">_n</span><span class="p">)]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">penalty</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">_m</span><span class="p">)</span> <span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span>  <span class="n">gradient</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
                    <span class="n">new_theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">new_theta_0</span><span class="p">,</span><span class="n">new_theta_rest</span><span class="p">))</span>


                <span class="k">else</span><span class="p">:</span>
                    <span class="n">gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span> <span class="p">(</span> <span class="n">y_pred</span> <span class="o">-</span> <span class="n">y_batch</span> <span class="p">)</span> <span class="o">*</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">)</span>
                    <span class="n">new_theta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span>  <span class="n">gradient</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">new_theta</span><span class="p">))</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">new_theta</span><span class="p">)):</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;breaking. found inf or nan.&quot;</span><span class="p">)</span>
                    <span class="k">break</span>
                <span class="c1"># override with new θ</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span> <span class="o">=</span> <span class="n">new_theta</span>

                <span class="c1"># calculate cost to put in history</span>
                <span class="n">cost</span> <span class="o">=</span> <span class="n">calculate_entropy_cost</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_batch</span><span class="p">),</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y_batch</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_cost_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>

                <span class="c1"># calcualted theta in history</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_theta_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_theta</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No Method Defined.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">target</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean radius</th>
      <th>mean texture</th>
      <th>mean perimeter</th>
      <th>mean area</th>
      <th>mean smoothness</th>
      <th>mean compactness</th>
      <th>mean concavity</th>
      <th>mean concave points</th>
      <th>mean symmetry</th>
      <th>mean fractal dimension</th>
      <th>...</th>
      <th>worst texture</th>
      <th>worst perimeter</th>
      <th>worst area</th>
      <th>worst smoothness</th>
      <th>worst compactness</th>
      <th>worst concavity</th>
      <th>worst concave points</th>
      <th>worst symmetry</th>
      <th>worst fractal dimension</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>17.99</td>
      <td>10.38</td>
      <td>122.80</td>
      <td>1001.0</td>
      <td>0.11840</td>
      <td>0.27760</td>
      <td>0.3001</td>
      <td>0.14710</td>
      <td>0.2419</td>
      <td>0.07871</td>
      <td>...</td>
      <td>17.33</td>
      <td>184.60</td>
      <td>2019.0</td>
      <td>0.1622</td>
      <td>0.6656</td>
      <td>0.7119</td>
      <td>0.2654</td>
      <td>0.4601</td>
      <td>0.11890</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>20.57</td>
      <td>17.77</td>
      <td>132.90</td>
      <td>1326.0</td>
      <td>0.08474</td>
      <td>0.07864</td>
      <td>0.0869</td>
      <td>0.07017</td>
      <td>0.1812</td>
      <td>0.05667</td>
      <td>...</td>
      <td>23.41</td>
      <td>158.80</td>
      <td>1956.0</td>
      <td>0.1238</td>
      <td>0.1866</td>
      <td>0.2416</td>
      <td>0.1860</td>
      <td>0.2750</td>
      <td>0.08902</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>19.69</td>
      <td>21.25</td>
      <td>130.00</td>
      <td>1203.0</td>
      <td>0.10960</td>
      <td>0.15990</td>
      <td>0.1974</td>
      <td>0.12790</td>
      <td>0.2069</td>
      <td>0.05999</td>
      <td>...</td>
      <td>25.53</td>
      <td>152.50</td>
      <td>1709.0</td>
      <td>0.1444</td>
      <td>0.4245</td>
      <td>0.4504</td>
      <td>0.2430</td>
      <td>0.3613</td>
      <td>0.08758</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>11.42</td>
      <td>20.38</td>
      <td>77.58</td>
      <td>386.1</td>
      <td>0.14250</td>
      <td>0.28390</td>
      <td>0.2414</td>
      <td>0.10520</td>
      <td>0.2597</td>
      <td>0.09744</td>
      <td>...</td>
      <td>26.50</td>
      <td>98.87</td>
      <td>567.7</td>
      <td>0.2098</td>
      <td>0.8663</td>
      <td>0.6869</td>
      <td>0.2575</td>
      <td>0.6638</td>
      <td>0.17300</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>20.29</td>
      <td>14.34</td>
      <td>135.10</td>
      <td>1297.0</td>
      <td>0.10030</td>
      <td>0.13280</td>
      <td>0.1980</td>
      <td>0.10430</td>
      <td>0.1809</td>
      <td>0.05883</td>
      <td>...</td>
      <td>16.67</td>
      <td>152.20</td>
      <td>1575.0</td>
      <td>0.1374</td>
      <td>0.2050</td>
      <td>0.4000</td>
      <td>0.1625</td>
      <td>0.2364</td>
      <td>0.07678</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 31 columns</p>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">feature_names</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
((569, 30), (569, 1))
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span><span class="n">accuracy_score</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>


<span class="n">X_i</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">feature_names</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>


<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_i</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Logitsic-Regression-without-Regression">
<h2>Logitsic Regression without Regression<a class="headerlink" href="#Logitsic-Regression-without-Regression" title="Permalink to this headline">¶</a></h2>
<div class="section" id="Batch-Gradient-Descent">
<h3>Batch Gradient Descent<a class="headerlink" href="#Batch-Gradient-Descent" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">logisitc_reg_model1</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span><span class="n">iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">logisitc_reg_model1</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;BGD&quot;</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">logisitc_reg_model1</span><span class="o">.</span><span class="n">y</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">logisitc_reg_model1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">logisitc_reg_model1</span><span class="o">.</span><span class="n">theta</span>
<span class="n">theta_history</span> <span class="o">=</span> <span class="n">logisitc_reg_model1</span><span class="o">.</span><span class="n">theta_history</span>
<span class="n">cost_history</span> <span class="o">=</span> <span class="n">logisitc_reg_model1</span><span class="o">.</span><span class="n">cost_history</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fit theta :&quot;</span><span class="p">,</span><span class="n">theta</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Confusion Matrix :</span>
<span class="si">{</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_pred</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span><span class="si">}</span><span class="s2"></span>
<span class="s2">Accuracy Score   :</span>
<span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_pred</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span><span class="si">}</span><span class="s2"></span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>


<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;iterations&quot;</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;loss :j(θ)&quot;</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cost_history</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;y_pred&quot;</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;y&quot;</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;loss: j(θ)&quot;</span><span class="p">,</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;θ&quot;</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">theta_history</span><span class="p">,</span><span class="n">cost_history</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
random initial θ value : [[3.43820676e-04 2.44234637e-04 8.47725902e-04 9.89584263e-04
  8.07625081e-05 6.63540762e-04 6.07785027e-04 8.64214692e-04
  2.32109312e-04 6.14707278e-04 5.80991051e-04 8.49034246e-04
  5.46092066e-04 9.69119288e-04 7.46816816e-04 3.33439672e-04
  7.35565522e-04 9.38340924e-04 2.82191206e-04 3.67408286e-04
  3.58850540e-05 4.87965118e-04 9.74260763e-04 9.14496325e-04
  6.73616246e-04 3.37368327e-04 4.17933103e-04 6.93937054e-04
  8.67834883e-04 4.08157926e-04 6.70602416e-04]]
Fit theta : [[ 0.4315998  -0.48964772 -0.50222963 -0.47967426 -0.49500558 -0.1875647
  -0.07384953 -0.40875014 -0.5264858  -0.10616663  0.26988978 -0.52549664
   0.00154857 -0.42177722 -0.45803567 -0.04403054  0.24807097  0.10826863
  -0.07833925  0.12907899  0.30277893 -0.62812932 -0.64870895 -0.59072385
  -0.59718205 -0.48696368 -0.21381106 -0.42197195 -0.57304068 -0.43079668
  -0.13505408]]

Confusion Matrix :
[[205   7]
 [  2 355]]
Accuracy Score   :
0.984182776801406

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/LogisticRegression_Explore_14_1.png" src="../_images/LogisticRegression_Explore_14_1.png" />
</div>
</div>
</div>
<div class="section" id="Stochastic-Gradient-Descent">
<h3>Stochastic Gradient Descent<a class="headerlink" href="#Stochastic-Gradient-Descent" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">logisitc_reg_model2</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span><span class="n">iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">logisitc_reg_model2</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;SGD&quot;</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">logisitc_reg_model2</span><span class="o">.</span><span class="n">y</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">logisitc_reg_model2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">logisitc_reg_model2</span><span class="o">.</span><span class="n">theta</span>
<span class="n">theta_history</span> <span class="o">=</span> <span class="n">logisitc_reg_model2</span><span class="o">.</span><span class="n">theta_history</span>
<span class="n">cost_history</span> <span class="o">=</span> <span class="n">logisitc_reg_model2</span><span class="o">.</span><span class="n">cost_history</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fit theta :&quot;</span><span class="p">,</span><span class="n">theta</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Confusion Matrix :</span>
<span class="si">{</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_pred</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span><span class="si">}</span><span class="s2"></span>
<span class="s2">Accuracy Score   :</span>
<span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_pred</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span><span class="si">}</span><span class="s2"></span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>


<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;iterations&quot;</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;loss :j(θ)&quot;</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cost_history</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;y_pred&quot;</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;y&quot;</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;loss: j(θ)&quot;</span><span class="p">,</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;θ&quot;</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">theta_history</span><span class="p">,</span><span class="n">cost_history</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
random initial θ value : [[4.41479798e-04 4.72812804e-04 2.24844495e-04 2.52188226e-04
  3.74074942e-04 5.70537261e-04 7.85943901e-04 4.72820141e-04
  4.55924113e-04 4.16492283e-04 3.82408490e-04 9.44135705e-04
  1.29332729e-04 5.64789391e-04 3.16377631e-04 7.38196916e-04
  7.43560933e-04 8.61175965e-04 8.70590693e-04 5.06208886e-04
  7.83172394e-05 1.90136784e-04 6.88824551e-04 7.85230465e-04
  7.80573678e-04 6.60524224e-04 2.88242723e-05 6.88352550e-04
  9.24426652e-04 7.85744968e-05 5.37121726e-04]]
Fit theta : [[ 0.42771334 -0.48810798 -0.50152412 -0.47890263 -0.49333594 -0.1853348
  -0.07251305 -0.4059144  -0.52516415 -0.1100023   0.26840855 -0.53028862
   0.0035719  -0.42656492 -0.45947704 -0.0388459   0.25399678  0.1078797
  -0.08428098  0.12971902  0.30779179 -0.62691221 -0.64391814 -0.58933645
  -0.59502922 -0.48699982 -0.21652376 -0.42142102 -0.57622444 -0.43416154
  -0.13581235]]

Confusion Matrix :
[[205   7]
 [  2 355]]
Accuracy Score   :
0.984182776801406

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/LogisticRegression_Explore_16_1.png" src="../_images/LogisticRegression_Explore_16_1.png" />
</div>
</div>
</div>
</div>
<div class="section" id="Logistic-Regression-with-Regularization">
<h2>Logistic Regression with Regularization<a class="headerlink" href="#Logistic-Regression-with-Regularization" title="Permalink to this headline">¶</a></h2>
<p><img alt="logistic_reg8" src="../_images/logistic_reg8.png" /></p>
<ul class="simple">
<li><p>Addressing Overfitting</p>
<ul>
<li><p>Reduce features</p>
<ul>
<li><p>manually select</p></li>
<li><p>model selection algorithm</p></li>
</ul>
</li>
<li><p>Regularization</p>
<ul>
<li><p>Keep all the features but reduce magnitude/values of parameter theta</p></li>
<li><p>Works well when we have a lot of features and each contributes a bit to predicting y</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img alt="logistic_reg10" src="../_images/logistic_reg10.png" /></p>
<div class="section" id="id1">
<h3>Stochastic Gradient Descent<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">logisitc_reg_model3</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span><span class="n">iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">logisitc_reg_model3</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;SGD&quot;</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span><span class="n">regularization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">penalty</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">logisitc_reg_model3</span><span class="o">.</span><span class="n">y</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">logisitc_reg_model3</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">logisitc_reg_model3</span><span class="o">.</span><span class="n">theta</span>
<span class="n">theta_history</span> <span class="o">=</span> <span class="n">logisitc_reg_model3</span><span class="o">.</span><span class="n">theta_history</span>
<span class="n">cost_history</span> <span class="o">=</span> <span class="n">logisitc_reg_model3</span><span class="o">.</span><span class="n">cost_history</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fit theta :&quot;</span><span class="p">,</span><span class="n">theta</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Confusion Matrix :</span>
<span class="si">{</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_pred</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span><span class="si">}</span><span class="s2"></span>
<span class="s2">Accuracy Score   :</span>
<span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_pred</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span><span class="si">}</span><span class="s2"></span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>


<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;iterations&quot;</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;loss :j(θ)&quot;</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cost_history</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;y_pred&quot;</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;y&quot;</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;loss: j(θ)&quot;</span><span class="p">,</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;θ&quot;</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">theta_history</span><span class="p">,</span><span class="n">cost_history</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
random initial θ value : [[5.19825530e-04 2.56134765e-04 4.91584163e-04 7.50997107e-04
  8.25121219e-04 4.33021824e-04 4.61548622e-05 4.46434801e-04
  6.21568202e-04 5.25479258e-04 8.47013069e-04 6.65760723e-04
  8.02776558e-04 9.45237426e-04 2.90484980e-04 3.18601539e-04
  2.91675714e-04 4.81967873e-04 9.04864690e-04 8.52410849e-05
  7.15320373e-04 4.81469781e-04 4.59864590e-04 5.55660238e-04
  8.94333121e-04 2.45143657e-04 4.17173704e-05 9.46852887e-04
  3.43192288e-04 7.63738254e-07 3.38543039e-04]]
Fit theta : [[ 0.51623671 -0.30850679 -0.29438282 -0.30370206 -0.29970758 -0.11393905
  -0.08213339 -0.2535341  -0.32390646 -0.07544541  0.15096525 -0.28867912
   0.00931243 -0.23586193 -0.24895518 -0.01071647  0.10312401  0.04529798
  -0.07163214  0.07115136  0.1479496  -0.37593874 -0.37311871 -0.35729218
  -0.34501709 -0.27574379 -0.16238925 -0.26571529 -0.35932896 -0.2603452
  -0.10132424]]

Confusion Matrix :
[[199  13]
 [  1 356]]
Accuracy Score   :
0.9753954305799648

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/LogisticRegression_Explore_19_1.png" src="../_images/LogisticRegression_Explore_19_1.png" />
</div>
</div>
</div>
<div class="section" id="id2">
<h3>Batch Gradient Descent<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">logisitc_reg_model4</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span><span class="n">iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">logisitc_reg_model4</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;BGD&quot;</span><span class="p">,</span><span class="n">regularization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">penalty</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">logisitc_reg_model4</span><span class="o">.</span><span class="n">y</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">logisitc_reg_model4</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">logisitc_reg_model4</span><span class="o">.</span><span class="n">theta</span>
<span class="n">theta_history</span> <span class="o">=</span> <span class="n">logisitc_reg_model4</span><span class="o">.</span><span class="n">theta_history</span>
<span class="n">cost_history</span> <span class="o">=</span> <span class="n">logisitc_reg_model4</span><span class="o">.</span><span class="n">cost_history</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fit theta :&quot;</span><span class="p">,</span><span class="n">theta</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Confusion Matrix :</span>
<span class="si">{</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_pred</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span><span class="si">}</span><span class="s2"></span>
<span class="s2">Accuracy Score   :</span>
<span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_pred</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span><span class="si">}</span><span class="s2"></span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>


<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;iterations&quot;</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;loss :j(θ)&quot;</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cost_history</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;y_pred&quot;</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;y&quot;</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;loss: j(θ)&quot;</span><span class="p">,</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;θ&quot;</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">theta_history</span><span class="p">,</span><span class="n">cost_history</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
random initial θ value : [[6.46660261e-04 3.88439846e-04 8.70254981e-05 6.49385296e-04
  2.94954815e-04 6.16950798e-04 7.81887247e-04 6.33693784e-04
  1.25202741e-04 6.01520289e-04 7.04939567e-04 5.81517466e-04
  4.60401273e-04 6.31197046e-04 3.69087881e-04 1.08115976e-04
  1.76891441e-04 4.72463299e-04 2.16930510e-04 4.10883291e-04
  6.08284943e-04 1.81311793e-04 2.50574954e-04 4.56421679e-04
  3.39055787e-04 9.51261146e-04 9.30382572e-04 4.20613075e-04
  9.10470954e-04 2.98184766e-04 3.34037216e-06]]
Fit theta : [[ 0.56113368 -0.25573136 -0.22787571 -0.25259736 -0.24257025 -0.10101348
  -0.09227762 -0.20080848 -0.26143928 -0.07107671  0.11375412 -0.21359598
   0.01085161 -0.17923597 -0.1855201   0.00251606  0.05404883  0.0318219
  -0.06782272  0.05134941  0.10657932 -0.29963945 -0.28257897 -0.28746323
  -0.26934137 -0.21298829 -0.14924521 -0.21219736 -0.29231033 -0.20462169
  -0.08327179]]

Confusion Matrix :
[[196  16]
 [  1 356]]
Accuracy Score   :
0.9701230228471002

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/LogisticRegression_Explore_21_1.png" src="../_images/LogisticRegression_Explore_21_1.png" />
</div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../TreeBasedModels/ExploreDecisionTree.html" class="btn btn-neutral float-right" title="Decision Tree Algorithm" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../LinearRegression/Explore.html" class="btn btn-neutral float-left" title="Linear Regression" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, Nishant Baheti

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>