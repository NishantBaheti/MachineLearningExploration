{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Algorithm\n",
    "Decision trees can be applied to both regression and classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_train_data = [\n",
    "    ['Green', 3, 'Apple'],\n",
    "    ['Yellow', 3, 'Apple'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Yellow', 3, 'Lemon'],\n",
    "]\n",
    "headers = ['color','diameter','fruit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART(Classification and Regression Trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question(Parition concept of the dataset)\n",
    "\n",
    "took from google example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question:\n",
    "    \n",
    "    def __init__(self,column_index,value,header):\n",
    "        self.column_index = column_index\n",
    "        self.value = value \n",
    "        self.header = header\n",
    "        \n",
    "    def match(self, example):\n",
    "        \"\"\"\n",
    "        Notes:\n",
    "            1. here example can be a numpy array of a list of size (size,)\n",
    "                because we are dealing with single row iteration for tree\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if isinstance(example,list):\n",
    "            example = np.array(example,dtype=\"O\")\n",
    "        val = example[self.column_index]\n",
    "        \n",
    "        if isinstance(val,(int,float,np.int64,np.float64)): # adding numpy int and float data types as well\n",
    "            return float(val) >= float(self.value) # a condition for question to return True or False for numeric value\n",
    "        else:\n",
    "            return str(val) == str(self.value) # categorical data comparison\n",
    "        \n",
    "    def __repr__(self):\n",
    "        \n",
    "        condition = \"==\"\n",
    "        if isinstance(self.value,(int,float,np.int64,np.float64)):\n",
    "            condition = \">=\"\n",
    "            \n",
    "        return f\"Is {self.header} {condition} {self.value} ?\"       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Is fruit == apple ?"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = Question(column_index=0,value='apple',header='fruit')\n",
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1.match(['apple',10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Is weight >= 30 ?"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2 = Question(column_index=1,value=30,header='weight')\n",
    "q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2.match(['apple',10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(rows,question):\n",
    "    \n",
    "    true_side, false_side = [],[]\n",
    "    for row in rows:\n",
    "        if question.match(row):\n",
    "            true_side.append(row)\n",
    "        else:\n",
    "            false_side.append(row)\n",
    "    return true_side, false_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['Red', 1, 'Grape'], ['Red', 1, 'Grape']],\n",
       " [['Green', 3, 'Apple'], ['Yellow', 3, 'Apple'], ['Yellow', 3, 'Lemon']])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition(dummy_train_data,Question(column_index=0,value='Red',header=headers[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini Impurity\n",
    "\n",
    "Used by the CART (classification and regression tree) algorithm for classification trees, Gini impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset. The Gini impurity can be computed by summing the probability $p_{i}$ of an item with label i being chosen times the probability \n",
    "\n",
    "$\\sum_{k \\neq i}{p_k} = 1 - {p_i}$\n",
    "\n",
    "of a mistake in categorizing that item. It reaches its minimum (zero) when all cases in the node fall into a single target category.\n",
    "\n",
    "$$\n",
    "{I_G(p)} = {\\sum_{i=1}^{J}{(p_i\\sum_{k \\neq i}p_k)}} = {\\sum_{i=1}^{J}p_i(1 - p_i)} = {\\sum_{i=1}^{J}(p_i - p_i^2)} = {\\sum_{i=1}^{J}p_i - \\sum_{i=1}^{J}p_i^2} = { 1 - \\sum_{i=1}^{J}p_i^2} \n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity(y):\n",
    "    \"\"\"\n",
    "    References:\n",
    "        https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity\n",
    "    \"\"\"\n",
    "    if isinstance(y,(list,tuple)):\n",
    "        y = np.array(y,dtype='O')\n",
    "        \n",
    "    if len(y.shape) == 1:\n",
    "        y = y.copy().reshape(-1,1)\n",
    "    \n",
    "    sum_val = 0\n",
    "    classes = np.unique(y[:,-1])\n",
    "    for cl in classes:\n",
    "        p = len(np.where(y == cl)[0])/ y.shape[0]\n",
    "        sum_val += p**2    \n",
    "    gini_score = 1 - sum_val\n",
    "    return gini_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4970414201183432\n"
     ]
    }
   ],
   "source": [
    "print(gini_impurity(np.array([0,0,0,0,0,0,0,1,1,1,1,1,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(gini_impurity(np.array(['apple','apple','apple','apple'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.375\n"
     ]
    }
   ],
   "source": [
    "print(gini_impurity(np.array(['apple','apple','apple','orange'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(gini_impurity(np.array(['apple','apple','apple','orange','orange','orange'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6122448979591837\n"
     ]
    }
   ],
   "source": [
    "print(gini_impurity(['apple','apple','apple','orange','orange','orange','lemon']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    if isinstance(y,(list,tuple)):\n",
    "        y = np.array(y,dtype='O')\n",
    "        \n",
    "    if len(y.shape) == 1:\n",
    "        y = y.copy().reshape(-1,1)\n",
    "    \n",
    "    entropy_score = 0\n",
    "    classes = np.unique(y)\n",
    "    for cl in classes:\n",
    "        p = len(np.where(y == cl)[0])/ y.shape[0]\n",
    "        entropy = -p * np.log2(p)\n",
    "        entropy_score += entropy\n",
    "        \n",
    "    return entropy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9957274520849255\n"
     ]
    }
   ],
   "source": [
    "print(entropy(np.array([0,0,0,0,0,0,0,1,1,1,1,1,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(entropy(np.array(['apple','apple','apple','apple'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8112781244591328\n"
     ]
    }
   ],
   "source": [
    "print(entropy(np.array(['apple','apple','apple','orange'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(entropy(np.array(['apple','apple','apple','orange','orange','orange'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5304930567574826\n"
     ]
    }
   ],
   "source": [
    "print(entropy(['apple','apple','apple','orange','orange','orange','lemon','lemon','apple']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(left_side, right_side, current_uncertainity):\n",
    "    \n",
    "    if isinstance(left_side,(list,tuple)):\n",
    "        left_side = np.array(left_side,dtype='O')\n",
    "    \n",
    "    if isinstance(right_side,(list,tuple)):\n",
    "        right_side = np.array(right_side,dtype='O')\n",
    "    \n",
    "    pr = left_side.shape[0] / (left_side.shape[0] + right_side.shape[0])\n",
    "    \n",
    "    info_gain_value = current_uncertainity - pr * gini_impurity(left_side) - ( 1 - pr ) * gini_impurity(right_side)\n",
    "    \n",
    "    return info_gain_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['color', 'diameter', 'fruit'],\n",
       " [['Green', 3, 'Apple'],\n",
       "  ['Yellow', 3, 'Apple'],\n",
       "  ['Red', 1, 'Grape'],\n",
       "  ['Red', 1, 'Grape'],\n",
       "  ['Yellow', 3, 'Lemon']])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers,dummy_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6399999999999999"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_uncert = gini_impurity(dummy_train_data)\n",
    "curr_uncert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts , fs = partition(dummy_train_data,Question(0,'Green',headers[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Green', 3, 'Apple']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Yellow', 3, 'Apple'],\n",
       " ['Red', 1, 'Grape'],\n",
       " ['Red', 1, 'Grape'],\n",
       " ['Yellow', 3, 'Lemon']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1399999999999999"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_gain(ts,fs,curr_uncert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts,fs = partition(dummy_train_data,Question(0,'Red',headers[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Red', 1, 'Grape'], ['Red', 1, 'Grape']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Green', 3, 'Apple'], ['Yellow', 3, 'Apple'], ['Yellow', 3, 'Lemon']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37333333333333324"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_gain(ts,fs,curr_uncert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best split in all options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(rows,headers):\n",
    "    \n",
    "    if not isinstance(rows,np.ndarray):\n",
    "        rows = np.array(rows,dtype='O')\n",
    "    \n",
    "    max_gain = 0\n",
    "    best_split_question = None\n",
    "    \n",
    "    current_inconsistency = gini_impurity(rows)\n",
    "    n = rows.shape[1] - 1 \n",
    "    \n",
    "    for col_index in range(n):\n",
    "        \n",
    "        unique_values = np.unique(rows[:,col_index])\n",
    "        for val in unique_values:\n",
    "            \n",
    "            ques = Question(column_index=col_index,value=val,header=headers[col_index])\n",
    "            \n",
    "            true_side,false_side = partition(rows,ques)\n",
    "            \n",
    "            if len(true_side) == 0 or len(false_side) == 0:\n",
    "                continue\n",
    "                \n",
    "            gain = info_gain(true_side, false_side, current_inconsistency)\n",
    "            \n",
    "            if gain >= max_gain:\n",
    "                max_gain,best_split_question = gain ,ques\n",
    "    return max_gain, best_split_question            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37333333333333324, Is diameter >= 3 ?)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_split(dummy_train_data,headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaf node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafNode:\n",
    "    def __init__(self, rows):\n",
    "        self.predictions = dict(zip(*np.unique(np.array(rows,dtype='O')[:,-1],return_counts=True)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    \n",
    "    def __init__(self,question,true_branch,false_branch):\n",
    "        \n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(rows,headers):\n",
    "    \n",
    "    if not isinstance(rows,np.ndarray):\n",
    "        rows = np.array(rows,dtype='O')\n",
    "    \n",
    "    gain, ques = find_best_split(rows,headers)\n",
    "    \n",
    "    if gain == 0:\n",
    "        return LeafNode(rows)\n",
    "\n",
    "    true_rows,false_rows = partition(rows,ques)\n",
    "    \n",
    "    true_branch = build_tree(true_rows,headers)\n",
    "    false_branch = build_tree(false_rows,headers)\n",
    "    \n",
    "    return DecisionNode(ques,true_branch,false_branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, spacing=\"\"):\n",
    "    \n",
    "    if isinstance(node,LeafNode):\n",
    "        print(spacing,\" Predict\", node.predictions)\n",
    "        return\n",
    "    \n",
    "    # Print the question at this node\n",
    "    print (spacing + str(node.question))\n",
    "\n",
    "    # Call this function recursively on the true branch\n",
    "    print (spacing + '--> True:')\n",
    "    print_tree(node.true_branch, spacing + \"  \")\n",
    "\n",
    "    # Call this function recursively on the false branch\n",
    "    print (spacing + '--> False:')\n",
    "    print_tree(node.false_branch, spacing + \"  \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Yellow' 3 'Apple']\n",
      " ['Yellow' 3 'Lemon']]\n",
      "{'Apple': 1, 'Lemon': 1}\n",
      "[['Green' 3 'Apple']]\n",
      "{'Apple': 1}\n",
      "[['Red' 1 'Grape']\n",
      " ['Red' 1 'Grape']]\n",
      "{'Grape': 2}\n"
     ]
    }
   ],
   "source": [
    "my_tree = build_tree(dummy_train_data,headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is diameter >= 3 ?\n",
      "--> True:\n",
      "  Is color == Yellow ?\n",
      "  --> True:\n",
      "      Predict {'Apple': 1, 'Lemon': 1}\n",
      "  --> False:\n",
      "      Predict {'Apple': 1}\n",
      "--> False:\n",
      "    Predict {'Grape': 2}\n"
     ]
    }
   ],
   "source": [
    "print_tree(my_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(row,node):\n",
    "    \n",
    "    if isinstance(node,LeafNode):\n",
    "        return node.predictions\n",
    "    \n",
    "    if node.question.match(row):\n",
    "        return classification(row,node.true_branch)\n",
    "    else:\n",
    "        return classification(row,node.false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Green', 3, 'Apple'],\n",
       " ['Yellow', 3, 'Apple'],\n",
       " ['Red', 1, 'Grape'],\n",
       " ['Red', 1, 'Grape'],\n",
       " ['Yellow', 3, 'Lemon']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple': 1}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification(dummy_train_data[0],my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple': 1, 'Lemon': 1}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification(dummy_train_data[1],my_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print leaf node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_leaf(results):\n",
    "    total = sum(results.values()) \n",
    "    \n",
    "    probs = {}\n",
    "    for key in results:\n",
    "        probs[key] = (results[key] / total) * 100\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple': 100.0}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_leaf(classification(dummy_train_data[0],my_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple': 50.0, 'Lemon': 50.0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_leaf(classification(dummy_train_data[1],my_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "dataset = load_iris()\n",
    "\n",
    "rows = np.hstack((dataset.data,dataset.target.reshape(-1,1)))\n",
    "headers = dataset.feature_names + ['target']\n",
    "\n",
    "my_tree = build_tree(rows,headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is petal width (cm) >= 1.0 ?\n",
      "--> True:\n",
      "  Is petal width (cm) >= 1.8 ?\n",
      "  --> True:\n",
      "    Is sepal length (cm) >= 5.8 ?\n",
      "    --> True:\n",
      "      Is sepal length (cm) >= 7.9 ?\n",
      "      --> True:\n",
      "          Predict {2.0: 1}\n",
      "      --> False:\n",
      "        Is petal length (cm) >= 4.9 ?\n",
      "        --> True:\n",
      "          Is petal width (cm) >= 2.1 ?\n",
      "          --> True:\n",
      "              Predict {2.0: 23}\n",
      "          --> False:\n",
      "            Is petal width (cm) >= 2.0 ?\n",
      "            --> True:\n",
      "                Predict {2.0: 3}\n",
      "            --> False:\n",
      "                Predict {2.0: 14}\n",
      "        --> False:\n",
      "          Is sepal width (cm) >= 3.2 ?\n",
      "          --> True:\n",
      "              Predict {1.0: 1}\n",
      "          --> False:\n",
      "              Predict {2.0: 2}\n",
      "    --> False:\n",
      "        Predict {2.0: 2}\n",
      "  --> False:\n",
      "    Is petal width (cm) >= 1.1 ?\n",
      "    --> True:\n",
      "      Is petal length (cm) >= 5.0 ?\n",
      "      --> True:\n",
      "        Is petal width (cm) >= 1.6 ?\n",
      "        --> True:\n",
      "          Is petal length (cm) >= 5.8 ?\n",
      "          --> True:\n",
      "              Predict {2.0: 1}\n",
      "          --> False:\n",
      "              Predict {1.0: 2}\n",
      "        --> False:\n",
      "            Predict {2.0: 3}\n",
      "      --> False:\n",
      "        Is petal width (cm) >= 1.7 ?\n",
      "        --> True:\n",
      "            Predict {2.0: 1}\n",
      "        --> False:\n",
      "            Predict {1.0: 40}\n",
      "    --> False:\n",
      "        Predict {1.0: 7}\n",
      "--> False:\n",
      "    Predict {0.0: 50}\n"
     ]
    }
   ],
   "source": [
    "print_tree(my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 100.0}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_leaf(classification(rows,my_tree))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
