{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4da9e41a-897b-4321-9e7c-e77c1e1ee531",
   "metadata": {},
   "source": [
    "# Probabilities Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c79c03-0c68-4a20-9927-f2007ceac841",
   "metadata": {},
   "source": [
    "`WIP`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645f4252-f90a-499d-95b0-5927dd6b8b41",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote04.html\n",
    "- https://en.wikipedia.org/wiki/Bayes%27_theorem\n",
    "- https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote05.html\n",
    "- https://en.wikipedia.org/wiki/Log_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc608ba3-01d3-4b31-a953-152c292763cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d1eb81-8403-4f2f-ab21-1981124927eb",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "P(X, Y) distribution P of data X & Y.\n",
    "\n",
    "* When we estimate P(X, Y) = P(X|Y) P(Y) = P(Y|X) P(X), called **Generative Learning**.\n",
    "* When we only estimate P(Y|X) directly, called **Discriminative Learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c180f6-62fb-4d41-a957-5467309ea717",
   "metadata": {},
   "source": [
    "**Scenario** Coin Toss\n",
    "\n",
    "Probability of getting heads P(H), when the coin is not a perfect one?\n",
    "\n",
    "number of tosses = 10\n",
    "\n",
    "10 samples are collected from tosses, D = { H, H, T, T, H, T, H, T, T, T }\n",
    "\n",
    "here $n_H$ = 4 and $n_T$ = 6, hence\n",
    "\n",
    "$P(H) \\approx \\frac{n_H}{n_H + n_T} = \\frac{4}{4 + 6} = 0.4$\n",
    "\n",
    "lets try to derive it..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f8e11-9b33-4997-86e2-2a9f53bab8bf",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimation(MLE)\n",
    "\n",
    "Estimation mentioned above in the scenario is actually **Maximum Likelihood Estimation**. P(H) is estimation of likelihood of getting heads.\n",
    "\n",
    "Steps for MLE-\n",
    "\n",
    "1. Modeling assumption about the type of distribution data is coming from.\n",
    "2. fitting the distribution parameter so that the sample/data observed is likely as possible.\n",
    "\n",
    "for coin toss example the distribution observed is binomial distribution {0, 1}. binom distribution has two parameters n and $\\theta$.\n",
    "\n",
    "\\begin{align}\n",
    "    b(x;n,\\theta) &= \\binom{n}{x}{\\theta^x}{(1-\\theta)}^{(n-x)}\\\\\n",
    "    \\\\\n",
    "    where \\\\\n",
    "    n &= \\text{number of random events}\\\\\n",
    "    \\theta &= \\text{probability of the event x}\n",
    "\\end{align}\n",
    "\n",
    "in the scenario's context\n",
    "\n",
    "\\begin{align}\n",
    "    P(D;\\theta) &= \\binom{n_H + n_T}{n_H}{\\theta^{n_H}}{(1-\\theta)}^{(n-n_H)}\\\\\n",
    "    \\\\\n",
    "    where \\\\\n",
    "    n &= \\text{number of independent bernoulli(binary) random events}\\\\\n",
    "    \\theta &= \\text{probability of heads coming up} = P(H)\n",
    "\\end{align}\n",
    "\n",
    "This translates to find a distribution $P(D|\\theta)$ which has two parameters n and $\\theta$ and it captures the distribution of n independent bernoulli random events(that generates random 0 and 1 ) such that $\\theta$ is the probability of the coin coming up with heads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645a2177-b1a8-4815-98ed-a062a6051a8f",
   "metadata": {},
   "source": [
    "### Principle\n",
    "\n",
    "find $\\hat{\\theta}$ to maximize the likelihood of the data, $P(D;\\theta)$:\n",
    "    \n",
    "$\\hat{\\theta}_{MLE} = {argmax\\atop{\\theta}} P(D; \\theta)$\n",
    "\n",
    "to maximize the value from a equation generally the derivative of the equation is solved while equating it to 0.\n",
    "\n",
    "two steps to solve above equation\n",
    "\n",
    "1. apply log to the function\n",
    "2. calculate derivative of equation and equate it to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b9311a-862c-44e3-b818-fc2c82b645e6",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    \\hat{\\theta}_{MLE} &= {argmax\\atop{\\theta}} P(D; \\theta)\\\\\n",
    "                       &= {argmax\\atop{\\theta}} \\binom{n_H + n_T}{n_H}{\\theta^{n_H}}{(1-\\theta)}^{(n_T)}\\\\\n",
    "                       &= {argmax\\atop{\\theta}} \\log{[ \\binom{n_H + n_T}{n_H}{\\theta^{n_H}}{(1-\\theta)}^{(n_T)}]}\\\\\n",
    "                       &= {argmax\\atop{\\theta}} \\log{[ \\binom{n_H + n_T}{n_H} ]} + \\log{[\\theta^{n_H}]} + \\log{[(1-\\theta)^{n_T}]}\\\\\n",
    "                       &\\downarrow \\frac{\\partial}{\\partial \\theta}\\text{ calculate derivative}\\\\\n",
    "    \\frac{n_H}{\\theta} + \\frac{n_T}{1 - \\theta} &= 0\\\\\n",
    "    \\hat{\\theta} &= \\frac{n_H}{n_H + n_T}\\\\\n",
    "    \\\\\n",
    "    \\text{where } \\theta \\in [0, 1]\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7efce3d-0cd2-4e12-8e56-8880f95cf233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['H', 'H', 'H', 'T', 'T', 'T', 'T', 'H', 'H', 'T', 'H', 'H', 'T',\n",
       "       'T', 'H', 'H', 'T', 'H', 'H', 'T', 'T', 'T', 'T', 'H', 'T', 'T',\n",
       "       'H', 'H', 'H', 'T', 'H', 'H', 'H', 'H', 'T', 'H', 'T', 'T', 'H',\n",
       "       'T', 'T', 'T', 'H', 'T', 'T', 'H', 'H', 'H', 'H', 'T', 'T', 'T',\n",
       "       'T', 'T', 'H', 'T', 'T', 'H', 'T', 'T', 'T', 'H', 'H', 'T', 'H',\n",
       "       'H', 'T', 'H', 'T', 'T', 'H', 'T', 'H', 'T', 'H', 'T', 'T', 'T',\n",
       "       'T', 'T', 'H', 'T', 'H', 'H', 'H', 'T', 'T', 'H', 'H', 'H', 'T',\n",
       "       'T', 'T', 'H', 'T', 'H', 'T', 'H', 'T', 'H'], dtype='<U1')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = [ \"T\", \"H\" ]\n",
    "n_events = 100\n",
    "D = np.random.choice(events, n_events)\n",
    "\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d19060d-d8af-4a85-bad9-82896b22bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "084a2476-2183-408d-bf46-5d992abc805d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'H': 47, 'T': 53}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = dict(zip(*np.unique(D, return_counts=True)))\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1e41018-e902-437d-99d6-0f36f53ec299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = n['H']/(n['H'] + n['T'])\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac664004-d8d4-40d7-a992-779953c6237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = binom(n=n, p=theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e797d8a8-3811-4ce6-9253-dce8161293fd",
   "metadata": {},
   "source": [
    "## Maximum A Posteriori Probability Estimation(MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28dccec-f58e-4c4b-b1ad-10b611e4eef0",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac7e3cb-42f3-45d8-b8b1-9f7ae48101f9",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    P(Y=y | X=x) &= \\frac{P(X=x | Y=y) P(Y=y)}{P(X=x)}\\\\\n",
    "    \\\\\n",
    "    &\\text{Where } \\\\\n",
    "    P(X=x | Y=y) &= \\prod_{\\alpha=1}^{d} P([X]_\\alpha = x_\\alpha| Y = y)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "- Naively assumes that all the features used are independently distrubuted variables given the label Y.\n",
    "- for example given that there is an email where all the words are independent given the label spam/ham."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff81344-978f-4e97-91a2-79e7b3fcc98d",
   "metadata": {},
   "source": [
    "## Bayes Classifier\n",
    "\n",
    "\\begin{align*}\n",
    "    h(\\vec{x}) &= {argmax\\atop{y}} \\frac{P(\\vec{x} | y) P(y)}{z}\\\\\n",
    "    \\\\\n",
    "    &= {argmax\\atop{y}} P(y) \\prod_{\\alpha} P([\\vec{X}]_\\alpha | y)\\\\\n",
    "    \\\\\n",
    "    &= {argmax\\atop{y}} ( log(P(y) + \\sum_\\alpha log P([\\vec{X}]_\\alpha | y))\n",
    "\\end{align*}\n",
    "\n",
    "P.S. - In computer science we dont prefer multiplying probabilities due to muliple reasons(see reference section). Hence we take log and convert multiplication to addition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
