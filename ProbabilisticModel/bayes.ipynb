{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbba87a9-a788-4bd0-a325-918e7105d93b",
   "metadata": {},
   "source": [
    "# Bayes Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d66b740e-7a67-45ff-b916-aae97de5bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84e4fb5-4882-40db-affb-7c9f7d6a7f4e",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote05.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "795d582d-bc17-4515-b60a-cbca14b0314b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>spam</td>\n",
       "      <td>PRIVATE! Your 2003 Account Statement for 07815...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>ham</td>\n",
       "      <td>Thanks chikku..:-) gud nyt:-*</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>spam</td>\n",
       "      <td>You are a winner U have been specially selecte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5275</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh yeah clearly it's my fault</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5481</th>\n",
       "      <td>ham</td>\n",
       "      <td>Shall call now dear having food</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  flag\n",
       "531   spam  PRIVATE! Your 2003 Account Statement for 07815...     1\n",
       "2919   ham                      Thanks chikku..:-) gud nyt:-*     0\n",
       "160   spam  You are a winner U have been specially selecte...     1\n",
       "5275   ham                      Oh yeah clearly it's my fault     0\n",
       "5481   ham                    Shall call now dear having food     0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('/opt/datasetsRepo/smsspamcollection/SMSSpamCollection', sep='\\t', names=['label', 'text'])\n",
    "dataset['flag'] = dataset['label'].map({ \"ham\" : 0, \"spam\" : 1})\n",
    "\n",
    "df = pd.concat([ \n",
    "    dataset.query('flag == 1').sample(50), \n",
    "    dataset.query('flag == 0').sample(50) \n",
    "], axis = 0).sample(frac=1, random_state=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa3e7e4f-b3aa-40dd-8fb7-c5a71381d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1ee2b25-1c86-45ae-aa37-62de0dd1d15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized'] = df['text'].apply(lambda x: [i for i in word_tokenize(x.lower()) if i not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41cabcd9-a826-4842-b057-73d3f75d655b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>flag</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>spam</td>\n",
       "      <td>PRIVATE! Your 2003 Account Statement for 07815...</td>\n",
       "      <td>1</td>\n",
       "      <td>[private, !, 2003, account, statement, 0781529...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>ham</td>\n",
       "      <td>Thanks chikku..:-) gud nyt:-*</td>\n",
       "      <td>0</td>\n",
       "      <td>[thanks, chikku, .., :, -, ), gud, nyt, :, -, *]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>spam</td>\n",
       "      <td>You are a winner U have been specially selecte...</td>\n",
       "      <td>1</td>\n",
       "      <td>[winner, u, specially, selected, 2, receive, £...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5275</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh yeah clearly it's my fault</td>\n",
       "      <td>0</td>\n",
       "      <td>[oh, yeah, clearly, 's, fault]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5481</th>\n",
       "      <td>ham</td>\n",
       "      <td>Shall call now dear having food</td>\n",
       "      <td>0</td>\n",
       "      <td>[shall, call, dear, food]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  flag  \\\n",
       "531   spam  PRIVATE! Your 2003 Account Statement for 07815...     1   \n",
       "2919   ham                      Thanks chikku..:-) gud nyt:-*     0   \n",
       "160   spam  You are a winner U have been specially selecte...     1   \n",
       "5275   ham                      Oh yeah clearly it's my fault     0   \n",
       "5481   ham                    Shall call now dear having food     0   \n",
       "\n",
       "                                              tokenized  \n",
       "531   [private, !, 2003, account, statement, 0781529...  \n",
       "2919   [thanks, chikku, .., :, -, ), gud, nyt, :, -, *]  \n",
       "160   [winner, u, specially, selected, 2, receive, £...  \n",
       "5275                     [oh, yeah, clearly, 's, fault]  \n",
       "5481                          [shall, call, dear, food]  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d557ea-d751-4d89-b69c-f0a2929e0191",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "\\begin{align}\n",
    "    P(Y=y | X=x) &= \\frac{P(X=x | Y=y) P(Y=y)}{P(X=x)}\\\\\n",
    "    \\\\\n",
    "    &\\text{Where } \\\\\n",
    "    P(X=x | Y=y) &= \\prod_{\\alpha=1}^{d} P([X]_\\alpha = x_\\alpha| Y = y)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "- Naively assumes that all the features used are independently distrubuted variables given the label Y.\n",
    "- for example given that there is an email where all the words are independent given the label spam/ham."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9e13da-4f72-4163-8ced-7bbfd5a6582e",
   "metadata": {},
   "source": [
    "## Bayes Classifier\n",
    "\n",
    "\\begin{align*}\n",
    "    h(\\vec{x}) &= {argmax\\atop{y}} \\frac{P(\\vec{x} | y) P(y)}{z}\\\\\n",
    "    \\\\\n",
    "    &= {argmax\\atop{y}} P(y) \\prod_{\\alpha} P([\\vec{X}]_\\alpha | y)\\\\\n",
    "    \\\\\n",
    "    &= {argmax\\atop{y}} ( log(P(y) + \\sum_\\alpha log P([\\vec{X}]_\\alpha | y))\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "P.S. - In computer science we dont prefer multiplying probabilities due to muliple reasons(see reference section). Hence we take log and convert multiplication to addition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
