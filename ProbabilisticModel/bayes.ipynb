{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbba87a9-a788-4bd0-a325-918e7105d93b",
   "metadata": {},
   "source": [
    "# Bayes Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84e4fb5-4882-40db-affb-7c9f7d6a7f4e",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote05.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66b740e-7a67-45ff-b916-aae97de5bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "795d582d-bc17-4515-b60a-cbca14b0314b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3807</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! We are trying to contact you. Last wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ü thk of wat to eat tonight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free 1st week entry 2 TEXTPOD 4 a chance 2 win...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "3807  spam  URGENT! We are trying to contact you. Last wee...\n",
       "4788   ham                       Ü thk of wat to eat tonight.\n",
       "1930  spam  Free 1st week entry 2 TEXTPOD 4 a chance 2 win..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('/opt/datasetsRepo/smsspamcollection/SMSSpamCollection', \n",
    "                      sep='\\t', names=['label', 'text'])\n",
    "# dataset['flag'] = dataset['label'].map({ \"ham\" : 0, \"spam\" : 1})\n",
    "\n",
    "df = pd.concat([ \n",
    "    dataset.query(\"label == 'spam'\").sample(50), \n",
    "    dataset.query(\"label == 'ham'\").sample(50) \n",
    "], axis = 0).sample(frac=1, random_state=0)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71811efa-603f-4730-9503-cbc8b9eaa2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0696f48-3ea3-4a8a-9d8c-7d2aba68431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08944ef5-a806-46ed-93d9-e43e0fa1be75",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = df['text'].apply(\n",
    "    lambda x: [i for i in tokenizer.tokenize(x.lower()) \\\n",
    "                  if i not in stop_words]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5932e55-2014-4450-8119-feee165235bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3807         urgent\n",
       "3807         trying\n",
       "3807        contact\n",
       "3807           last\n",
       "3807       weekends\n",
       "           ...     \n",
       "2438            net\n",
       "2438       custcare\n",
       "2438    08715705022\n",
       "2438         1x150p\n",
       "2438             wk\n",
       "Name: text, Length: 1259, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict.explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95ae3ea5-83f5-4ef3-bd89-a2088826a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = df[['label','text']].groupby('label', group_keys=False)['text']\\\n",
    ".apply(lambda x: \" \".join(x))\\\n",
    ".apply(lambda x: nltk.FreqDist([i for i in tokenizer.tokenize(x.lower()) \\\n",
    "                  if i not in stop_words]))\\\n",
    ".to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a28ba7f-e782-4921-b8b3-c5bcfb5c76bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'lor': 6, 'like': 6, 'u': 5, 'got': 5, 'wat': 4, 'go': 4, 'ur': 3, 'come': 3, 'lt': 3, 'gt': 3, ...})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict['ham']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d557ea-d751-4d89-b69c-f0a2929e0191",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "\\begin{align}\n",
    "P(Y=y | X=x) &= \\frac{P(X=x | Y=y) P(Y=y)}{P(X=x)}\\\\\n",
    "\\\\\n",
    "&\\text{Where } \\\\\n",
    "P(X=x | Y=y) &= \\prod_{\\alpha=1}^{d} P([X]_\\alpha = x_\\alpha| Y = y)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "- Naively assumes that all the features used are independently distrubuted variables given the label Y.\n",
    "- for example given that there is an email where all the words are independent given the label spam/ham."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9e13da-4f72-4163-8ced-7bbfd5a6582e",
   "metadata": {},
   "source": [
    "## Bayes Classifier\n",
    "\n",
    "\\begin{align*}\n",
    "h(\\vec{x}) &= {argmax\\atop{y}} \\frac{P(\\vec{x} | y) P(y)}{z}\\\\\n",
    "\\\\\n",
    "&= {argmax\\atop{y}} P(y) \\prod_{\\alpha} P([\\vec{X}]_\\alpha | y)\\\\\n",
    "\\\\\n",
    "&= {argmax\\atop{y}} ( log(P(y) + \\sum_\\alpha log P([\\vec{X}]_\\alpha | y))\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "P.S. - In computer science we dont prefer multiplying probabilities due to muliple reasons(see reference section). Hence we take log and convert multiplication to addition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213cf101-da27-44e0-a20b-5167e31a91fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
